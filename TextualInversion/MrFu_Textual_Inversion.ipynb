{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k2l1NrzIPzuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8126b3-e4e6-4af6-d650-5cdc6e5aae47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPackage installation finished.\n"
          ]
        }
      ],
      "source": [
        "# 1. Install the required packages\n",
        "# On Windows, you just need to execute this cell for once.\n",
        "try:\n",
        "    import google.colab\n",
        "    # IN_COLAB = True\n",
        "except ImportError:\n",
        "    # IN_COLAB = False\n",
        "    %pip install -q git+https://github.com/huggingface/transformers\n",
        "    %pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "%pip install -q git+https://github.com/huggingface/diffusers\n",
        "%pip install -q gradio ftfy tensorboard\n",
        "%pip install -q bitsandbytes\n",
        "#%pip install -U git+https://github.com/TimDettmers/bitsandbytes.git\n",
        "%pip install -q xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "#%pip install -U git+https://github.com/facebookresearch/xformers.git@main\n",
        "print(\"Package installation finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9gVoVoNmnsrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7446e5a-aa27-4b0c-fb4d-778f371ef0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-26 12:16:37--  https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/TextualInversion/textual_inversion.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41602 (41K) [text/plain]\n",
            "Saving to: ‘textual_inversion.py’\n",
            "\n",
            "textual_inversion.p 100%[===================>]  40.63K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-03-26 12:16:37 (4.68 MB/s) - ‘textual_inversion.py’ saved [41602/41602]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2. Create folders and download training scripts\n",
        "import os, shutil\n",
        "\n",
        "#global variables\n",
        "dataset_dir = \"./dataset\"\n",
        "output_dir = \"./output\"\n",
        "logging_dir = \"./logs\"\n",
        "\n",
        "token_name = \"sks\"\n",
        "\n",
        "available_models = {\n",
        "    \"SD v1.5\": \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "    # \"SDXL\": \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "}\n",
        "\n",
        "def reset_data():\n",
        "  # Create the directories if they don't exist\n",
        "  # shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "  os.makedirs(dataset_dir, exist_ok=True)\n",
        "  # Delete the 'output' folder and its contents\n",
        "  shutil.rmtree(output_dir, ignore_errors=True)\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "  # Delete the 'log' folder and its contents\n",
        "  shutil.rmtree(logging_dir, ignore_errors=True)\n",
        "  os.makedirs(logging_dir, exist_ok=True)\n",
        "  # Delete the 'dataset' folder and its contents\n",
        "  # shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "  # os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "  # fetch textual inversion code if it doesn't exist\n",
        "  if not os.path.exists(\"textual_inversion.py\"):\n",
        "      !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/TextualInversion/textual_inversion.py\n",
        "  else:\n",
        "      print(\"textual_inversion.py already exists, skipping download.\")\n",
        "\n",
        "  ipynb_checkpoints = os.path.join( dataset_dir, \".ipynb_checkpoints\")\n",
        "  shutil.rmtree(\".gradio\", ignore_errors=True)\n",
        "  shutil.rmtree(\".config\", ignore_errors=True)\n",
        "  shutil.rmtree(ipynb_checkpoints, ignore_errors=True)\n",
        "\n",
        "reset_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0wl0d-1HlRJZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "0b2939c1-ed1a-444c-8209-a8aec994c088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5b16f878da76c50790.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5b16f878da76c50790.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from textual_inversion import main as train_textual_inversion\n",
        "from textual_inversion import parse_args\n",
        "# from textual_inversion_sdxl import main as train_textaul_inversion_sdxl\n",
        "# from textual_inversion_sdxl import parse_args as parse_args_sdxl\n",
        "import threading, os, logging, time\n",
        "from os import path\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status, max_train_steps, current_step\n",
        "    current_step = step\n",
        "    current_preview = image\n",
        "    # current_status = f\"Preview updated at step {step}\"\n",
        "    # current_preview.show()\n",
        "    print(f\"{step}/{max_train_steps}\")\n",
        "\n",
        "def stop_training():\n",
        "  global stop_flag\n",
        "  stop_flag.set()\n",
        "  return gr.update(value=\"Training stopped.\")\n",
        "\n",
        "def run_training(model_name, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                 learning_rate, batch_size, preview_save_steps, preview_seed):\n",
        "    global current_preview, current_status, token_name\n",
        "    global max_train_steps, current_step, finish_event, stop_flag\n",
        "    current_preview = None  # Reset the preview\n",
        "    token_name = placeholder_token\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "\n",
        "    # Construct the command with all arguments\n",
        "    command = [\n",
        "        # \"python\", \"textual_inversion.py\",\n",
        "        \"--pretrained_model_name_or_path\", available_models[model_name],\n",
        "        \"--train_data_dir\", dataset_dir,\n",
        "        \"--placeholder_token\", placeholder_token,\n",
        "        \"--initializer_token\", initializer_token,\n",
        "        \"--resolution\", str(512),\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--gradient_accumulation_steps\", \"1\",\n",
        "        \"--learning_rate\", str(learning_rate),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--save_steps\", str(preview_save_steps),\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--output_dir\", output_dir,\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--learnable_property\", \"object\",\n",
        "        \"--seed\", str(preview_seed),\n",
        "        \"--mixed_precision\", \"fp16\",\n",
        "        \"--enable_xformers_memory_efficient_attention\"\n",
        "    ]\n",
        "\n",
        "    # Print the command for debugging\n",
        "    # print(\"Command:\", \" \".join(command))\n",
        "\n",
        "    # Disable logging\n",
        "    # logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    # Run the command in a separate process\n",
        "    # process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Run the command as function\n",
        "    # if model_name == \"SDXL\":\n",
        "    #     args = parse_args_sdxl(command)\n",
        "    # else:\n",
        "    args = parse_args(command)\n",
        "\n",
        "    yield gr.update(value=None), gr.update(value=\" \".join(command))\n",
        "\n",
        "    max_train_steps = args.max_train_steps\n",
        "\n",
        "    def worker(finish_event, stop_flag):\n",
        "      try:\n",
        "        train_textual_inversion(args, {\"_callback\": preview_callback, \"stop_flag\": stop_flag})\n",
        "      except Exception as e:\n",
        "        print(f\"Training error: {e}\")\n",
        "      finally:\n",
        "        finish_event.set()\n",
        "\n",
        "    finish_event = threading.Event()\n",
        "    stop_flag = threading.Event()\n",
        "    finish_event.clear()\n",
        "    stop_flag.clear()\n",
        "\n",
        "    train_thread = threading.Thread(target=worker, args=(finish_event, stop_flag))\n",
        "    train_thread.start()\n",
        "    yield gr.update(value=None), gr.update(value=f\"Training started.\")\n",
        "\n",
        "    # except Exception as e:\n",
        "    #   print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "    while not finish_event.is_set():\n",
        "        if current_preview is not None:\n",
        "            yield gr.update(value=current_preview), gr.update(value=f\"Preview at {current_step} step.\")\n",
        "            current_preview = None\n",
        "        time.sleep(1)\n",
        "\n",
        "    train_thread.join()\n",
        "\n",
        "    # Print the output and errors (for debugging)\n",
        "    # print(\"Output:\", stdout.decode())\n",
        "    # print(\"Errors:\", stderr.decode())\n",
        "\n",
        "    # Update status when training completes\n",
        "    current_status = \"Training completed!\"\n",
        "\n",
        "    yield gr.update(), gr.update(value=current_status)\n",
        "\n",
        "\n",
        "# Define a function to move the selected file\n",
        "def copy_file(target_directory, file_path):\n",
        "  if file_path is not None:\n",
        "      filename = os.path.basename(file_path)\n",
        "      destination_path = os.path.join(target_directory, filename)\n",
        "      # test if the destination_path alread exist\n",
        "      if not os.path.exists(destination_path):\n",
        "        shutil.copy(file_path, destination_path)\n",
        "        print(f\"Copy {filename} to {target_directory}\")\n",
        "      else:\n",
        "        print(f\"{filename} already exists.\")\n",
        "  else:\n",
        "      print(\"No file selected.\")\n",
        "\n",
        "def process_files(files):\n",
        "    file_info = []\n",
        "\n",
        "    for file in files:\n",
        "        fileBasename = os.path.basename(file)\n",
        "        destination_path = os.path.join(dataset_dir, fileBasename)\n",
        "        if not os.path.exists(destination_path):\n",
        "            file_info.append(f\"File: {file.name}\")\n",
        "            copy_file(dataset_dir, file.name )\n",
        "    return f\"{len(file_info)} files uploaded.\"\n",
        "\n",
        "def delete_dataset():\n",
        "  shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "  os.makedirs(dataset_dir, exist_ok=True)\n",
        "  return \"Dataset deleted.\"\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion Textual Inversion UI\")\n",
        "        gr.Markdown(\"Generate images using a preloaded textual inversion model.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            model_name = gr.Dropdown(\n",
        "                label=\"Model Name\",\n",
        "                choices=available_models.keys(),\n",
        "                value= list(available_models.keys())[0] if available_models.keys() else \"Select a Model\",\n",
        "                interactive=True\n",
        "            )\n",
        "\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(file_count=\"multiple\", label=\"Upload Files\")\n",
        "        with gr.Row():\n",
        "            submit_btn = gr.Button(\"Upload Files\")\n",
        "            delete_data_btn = gr.Button(\"Delete Dataset\")\n",
        "        with gr.Row():\n",
        "            output = gr.Textbox(label=\"Results\")\n",
        "        submit_btn.click(fn=process_files, inputs=file_input, outputs=output)\n",
        "        delete_data_btn.click(fn=delete_dataset, outputs=output)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                placeholder_token = gr.Textbox(label=\"Placeholder Token\", value=\"\", placeholder=\"Enter placeholder token here\", interactive=True)\n",
        "                initializer_token = gr.Textbox(label=\"Initializer Token\", value=\"\", placeholder=\"Enter initializer token here\", interactive=True)\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\", value=\"\", placeholder=\"Enter your prompt here\", interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps\", value=1000, interactive=True)\n",
        "                learning_rate = gr.Number(label=\"Learning Rate\", value=0.001, interactive=True)\n",
        "                batch_size = gr.Number(label=\"Batch Size\", value=1, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview/Save Every N Steps\", value=10, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "                generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "                generate_button = gr.Button(\"Start Training\")\n",
        "                cancel_button = gr.Button(\"Cancel Training\")\n",
        "                reset_button = gr.Button(\"Reset Data\")\n",
        "\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[model_name, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                    learning_rate, batch_size, preview_save_steps, preview_seed],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "        cancel_button.click(\n",
        "            fn=stop_training,\n",
        "            outputs=[generate_status]\n",
        "        )\n",
        "\n",
        "        reset_button.click(\n",
        "            fn=reset_data\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "demo = ui()\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp4gds97p4b1"
      },
      "outputs": [],
      "source": [
        "demo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGHQoyANX7aP"
      },
      "outputs": [],
      "source": [
        "# 7. Download your model.savetensors\n",
        "# If you are using Colab, you can mount Google Drive and upload your model.safetensors\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Create a directory in Google Drive if it doesn't exist\n",
        "    import os\n",
        "    target_dir = \"/content/drive/MyDrive/TextualInversion\"\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "        print(f\"Created directory: {target_dir}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {target_dir}\")\n",
        "\n",
        "    # Copy your file to Drive\n",
        "    !cp /content/{token_name}.safetensors {target_dir}/{token_name}.safetensors\n",
        "    print(f\"Your Textual Inversion model has been uploaded to your Google Drive folder {target_dir}\")\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7luCZ7oRmLI",
        "outputId": "1a1d97da-a778-4932-b882-dafd6e365b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File sks (2).png saved to ./dataset\n",
            "File sks (3).png saved to ./dataset\n",
            "File sks (4).png saved to ./dataset\n",
            "File sks (5).png saved to ./dataset\n",
            "File sks (6).png saved to ./dataset\n",
            "File sks (1).jpg saved to ./dataset\n",
            "File sks (7).png saved to ./dataset\n"
          ]
        }
      ],
      "source": [
        "# 3. Upload dataset images\n",
        "def load_dataset():\n",
        "  try:\n",
        "    from google.colab import files\n",
        "    import os\n",
        "\n",
        "    # Upload files from local machine\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move the uploaded files to the target directory\n",
        "    for filename in uploaded.keys():\n",
        "        # Get source and destination paths\n",
        "        source_path = filename\n",
        "        destination_path = os.path.join(dataset_dir, filename)\n",
        "\n",
        "        # Move the file\n",
        "        !cp \"{source_path}\" \"{destination_path}\"\n",
        "        print(f\"Moved {filename} to {dataset_dir}\")\n",
        "\n",
        "  except ImportError:\n",
        "    import tkinter as tk\n",
        "    from tkinter import filedialog\n",
        "    import os\n",
        "\n",
        "    # Initialize tkinter\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()  # Hide the root window\n",
        "    root.attributes('-topmost',True)\n",
        "\n",
        "    # Open a file dialog and allow multiple file selection\n",
        "    file_paths = filedialog.askopenfilenames(\n",
        "        title='Select Dataset Images',\n",
        "        filetypes=[('Image Files', '*.png;*.jpg;*.jpeg;*.bmp;*.gif')]\n",
        "    )\n",
        "    root.destroy()\n",
        "\n",
        "    # Define the target directory\n",
        "    target_directory = dataset_dir\n",
        "\n",
        "    # Copy or move files to the target directory\n",
        "    for file_path in file_paths:\n",
        "        filename = os.path.basename(file_path)\n",
        "        destination = os.path.join(target_directory, filename)\n",
        "        os.rename(file_path, destination)  # or use shutil.copy for copying\n",
        "        print(f'File {filename} saved to {target_directory}')\n",
        "\n",
        "load_dataset()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}