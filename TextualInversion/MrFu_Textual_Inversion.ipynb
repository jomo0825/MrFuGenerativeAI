{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Install the required packages\n",
        "# On Windows, you just need to execute this cell for once.\n",
        "try:\n",
        "    import google.colab\n",
        "    # IN_COLAB = True\n",
        "except ImportError:\n",
        "    # IN_COLAB = False\n",
        "    %pip install -q git+https://github.com/huggingface/transformers\n",
        "    %pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "%pip install -q git+https://github.com/huggingface/diffusers\n",
        "%pip install -q gradio ftfy tensorboard\n",
        "%pip install -q bitsandbytes\n",
        "#%pip install -U git+https://github.com/TimDettmers/bitsandbytes.git\n",
        "%pip install -q xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "#%pip install -U git+https://github.com/facebookresearch/xformers.git@main\n",
        "print(\"Package installation finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gVoVoNmnsrN",
        "outputId": "e399264c-18b3-499e-e68d-d23235c6fc74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "textual_inversion.py already exists, skipping download.\n"
          ]
        }
      ],
      "source": [
        "# 2. Create folders and download training scripts\n",
        "import os, shutil\n",
        "\n",
        "dataset_dir = \"./dataset\"\n",
        "output_dir = \"./output\"\n",
        "logging_dir = \"./logs\"\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "# Delete the 'output' folder and its contents\n",
        "shutil.rmtree(output_dir, ignore_errors=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "# Delete the 'log' folder and its contents\n",
        "shutil.rmtree(logging_dir, ignore_errors=True)\n",
        "os.makedirs(logging_dir, exist_ok=True)\n",
        "# Delete the 'dataset' folder and its contents\n",
        "# shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "# os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# fetch textual inversion code if it doesn't exist\n",
        "if not os.path.exists(\"textual_inversion.py\"):\n",
        "    !wget https://raw.githubusercontent.com/jomo0825/MrFuTextualInversion/main/textual_inversion.py\n",
        "else:\n",
        "    print(\"textual_inversion.py already exists, skipping download.\")\n",
        "\n",
        "ipynb_checkpoints = os.path.join( dataset_dir, \".ipynb_checkpoints\")\n",
        "shutil.rmtree(\".gradio\", ignore_errors=True)\n",
        "shutil.rmtree(\".config\", ignore_errors=True)\n",
        "shutil.rmtree(ipynb_checkpoints, ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0wl0d-1HlRJZ",
        "outputId": "b3e842ab-1699-418e-f4ff-dc41721eb60c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A matching Triton is not available, some optimizations will not be enabled\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\n",
            "    import triton  # noqa\n",
            "ModuleNotFoundError: No module named 'triton'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "03/24/2025 20:55:07 - INFO - textual_inversion - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "{'timestep_spacing', 'dynamic_thresholding_ratio', 'variance_type', 'sample_max_value', 'thresholding', 'prediction_type', 'rescale_betas_zero_snr', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "Instantiating AutoencoderKL model under default dtype torch.float32.\n",
            "{'scaling_factor', 'mid_block_add_attention', 'use_quant_conv', 'latents_mean', 'force_upcast', 'latents_std', 'shift_factor', 'use_post_quant_conv'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "Instantiating UNet2DConditionModel model under default dtype torch.float32.\n",
            "{'transformer_layers_per_block', 'conv_in_kernel', 'conv_out_kernel', 'upcast_attention', 'attention_type', 'encoder_hid_dim_type', 'addition_time_embed_dim', 'resnet_time_scale_shift', 'time_cond_proj_dim', 'only_cross_attention', 'encoder_hid_dim', 'addition_embed_type_num_heads', 'cross_attention_norm', 'reverse_transformer_layers_per_block', 'num_attention_heads', 'class_embed_type', 'mid_block_type', 'mid_block_only_cross_attention', 'dropout', 'class_embeddings_concat', 'resnet_skip_time_act', 'dual_cross_attention', 'addition_embed_type', 'timestep_post_act', 'num_class_embeds', 'time_embedding_type', 'resnet_out_scale_factor', 'use_linear_projection', 'time_embedding_act_fn', 'projection_class_embeddings_input_dim', 'time_embedding_dim'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "03/24/2025 20:55:15 - INFO - textual_inversion - ***** Running training *****\n",
            "03/24/2025 20:55:15 - INFO - textual_inversion -   Num examples = 400\n",
            "03/24/2025 20:55:15 - INFO - textual_inversion -   Num Epochs = 1\n",
            "03/24/2025 20:55:15 - INFO - textual_inversion -   Instantaneous batch size per device = 1\n",
            "03/24/2025 20:55:15 - INFO - textual_inversion -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "03/24/2025 20:55:15 - INFO - textual_inversion -   Gradient Accumulation steps = 1\n",
            "03/24/2025 20:55:15 - INFO - textual_inversion -   Total optimization steps = 50\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "651e9650aa0943c4a90b8f43d22418cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Steps:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "03/24/2025 20:55:22 - INFO - textual_inversion - Saving embeddings\n",
            "03/24/2025 20:55:22 - INFO - textual_inversion - Running validation... \n",
            " Generating 1 images with prompt: sks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log_validation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e2ffbf91e9845bebd3563d77482545f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "{'solver_order', 'lambda_min_clipped', 'timestep_spacing', 'variance_type', 'use_karras_sigmas', 'algorithm_type', 'thresholding', 'lower_order_final', 'euler_at_final', 'use_beta_sigmas', 'final_sigmas_type', 'use_lu_lambdas', 'dynamic_thresholding_ratio', 'sample_max_value', 'use_exponential_sigmas', 'prediction_type', 'flow_shift', 'use_flow_sigmas', 'solver_type', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
            "03/24/2025 20:55:33 - INFO - textual_inversion - Saving embeddings\n",
            "03/24/2025 20:55:33 - INFO - textual_inversion - Running validation... \n",
            " Generating 1 images with prompt: sks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log_validation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "275249f320874f9e9fb8e9171cf5a5b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "{'solver_order', 'lambda_min_clipped', 'timestep_spacing', 'variance_type', 'use_karras_sigmas', 'algorithm_type', 'thresholding', 'lower_order_final', 'euler_at_final', 'use_beta_sigmas', 'final_sigmas_type', 'use_lu_lambdas', 'dynamic_thresholding_ratio', 'sample_max_value', 'use_exponential_sigmas', 'prediction_type', 'flow_shift', 'use_flow_sigmas', 'solver_type', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
            "03/24/2025 20:55:43 - INFO - textual_inversion - Saving embeddings\n",
            "03/24/2025 20:55:43 - INFO - textual_inversion - Running validation... \n",
            " Generating 1 images with prompt: sks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log_validation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "920ad9dad7fc4e74bd3722cd3a0917a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "{'solver_order', 'lambda_min_clipped', 'timestep_spacing', 'variance_type', 'use_karras_sigmas', 'algorithm_type', 'thresholding', 'lower_order_final', 'euler_at_final', 'use_beta_sigmas', 'final_sigmas_type', 'use_lu_lambdas', 'dynamic_thresholding_ratio', 'sample_max_value', 'use_exponential_sigmas', 'prediction_type', 'flow_shift', 'use_flow_sigmas', 'solver_type', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
            "03/24/2025 20:55:53 - INFO - textual_inversion - Saving embeddings\n",
            "03/24/2025 20:55:53 - INFO - textual_inversion - Running validation... \n",
            " Generating 1 images with prompt: sks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log_validation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf67dbf58e824b9eb48ae8e2819d1d67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "{'solver_order', 'lambda_min_clipped', 'timestep_spacing', 'variance_type', 'use_karras_sigmas', 'algorithm_type', 'thresholding', 'lower_order_final', 'euler_at_final', 'use_beta_sigmas', 'final_sigmas_type', 'use_lu_lambdas', 'dynamic_thresholding_ratio', 'sample_max_value', 'use_exponential_sigmas', 'prediction_type', 'flow_shift', 'use_flow_sigmas', 'solver_type', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
            "03/24/2025 20:56:03 - INFO - textual_inversion - Saving embeddings\n",
            "03/24/2025 20:56:03 - INFO - textual_inversion - Running validation... \n",
            " Generating 1 images with prompt: sks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log_validation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45cbf8b24528471db5566b67fa53d82a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "{'solver_order', 'lambda_min_clipped', 'timestep_spacing', 'variance_type', 'use_karras_sigmas', 'algorithm_type', 'thresholding', 'lower_order_final', 'euler_at_final', 'use_beta_sigmas', 'final_sigmas_type', 'use_lu_lambdas', 'dynamic_thresholding_ratio', 'sample_max_value', 'use_exponential_sigmas', 'prediction_type', 'flow_shift', 'use_flow_sigmas', 'solver_type', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
            "03/24/2025 20:56:06 - INFO - textual_inversion - Saving embeddings\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from textual_inversion import main as train_textaul_inversion\n",
        "from textual_inversion import parse_args as parse_args\n",
        "import threading, os, logging, time\n",
        "from os import path\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status, max_train_steps, current_step\n",
        "    current_step = step\n",
        "    current_preview = image\n",
        "    # current_status = f\"Preview updated at step {step}\"\n",
        "    # current_preview.show()\n",
        "    # print(f\"{step}/{max_train_steps}\")\n",
        "\n",
        "\n",
        "def run_training(dataset_path, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                 learning_rate, batch_size, preview_save_steps, preview_seed):\n",
        "    global current_preview, current_status\n",
        "    global max_train_steps, current_step\n",
        "    current_preview = None  # Reset the preview\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "\n",
        "    # Construct the command with all arguments\n",
        "    command = [\n",
        "        # \"python\", \"textual_inversion.py\",\n",
        "        \"--pretrained_model_name_or_path\", \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "        \"--train_data_dir\", dataset_path,\n",
        "        \"--placeholder_token\", placeholder_token,\n",
        "        \"--initializer_token\", initializer_token,\n",
        "        \"--resolution\", \"512\",\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--gradient_accumulation_steps\", \"1\",\n",
        "        \"--learning_rate\", str(learning_rate),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--save_steps\", str(preview_save_steps),\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--output_dir\", output_dir,\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--learnable_property\", \"object\",\n",
        "        \"--seed\", str(preview_seed)\n",
        "    ]\n",
        "\n",
        "    # Print the command for debugging\n",
        "    # print(\"Command:\", \" \".join(command))\n",
        "\n",
        "    # Create the directories if they don't exist\n",
        "    os.makedirs(logging_dir, exist_ok=True)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Disable logging\n",
        "    logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    # Run the command in a separate process\n",
        "    # process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Run the command as function\n",
        "    args = parse_args(command)\n",
        "    max_train_steps = args.max_train_steps\n",
        "    # train_textaul_inversion(args, {\"_callback\": preview_callback})\n",
        "\n",
        "    def worker(finish_event):\n",
        "        train_textaul_inversion(args, {\"_callback\": preview_callback})\n",
        "        finish_event.set()\n",
        "\n",
        "    finish_event = threading.Event()\n",
        "    finish_event.clear()\n",
        "    train_thread = threading.Thread(target=worker, args=(finish_event,))                                \n",
        "    train_thread.start()\n",
        "\n",
        "    # Wait for the process to complete\n",
        "    # stdout, stderr = process.communicate()\n",
        "    while not finish_event.is_set():\n",
        "        if current_preview is not None:\n",
        "            yield gr.update(value=current_preview), gr.update(value=f\"Preview at {current_step} step.\")\n",
        "            current_preview = None\n",
        "        time.sleep(1)\n",
        "\n",
        "    train_thread.join()\n",
        "    # Print the output and errors (for debugging)\n",
        "    # print(\"Output:\", stdout.decode())\n",
        "    # print(\"Errors:\", stderr.decode())\n",
        "\n",
        "    # Update status when training completes\n",
        "    current_status = \"Training completed!\"\n",
        "\n",
        "    yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion Textual Inversion UI\")\n",
        "        gr.Markdown(\"Generate images using a preloaded textual inversion model.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            dataset_path = gr.Textbox(label=\"Dataset Path\", value=\"dataset\", interactive=True)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                placeholder_token = gr.Textbox(label=\"Placeholder Token\", placeholder=\"Enter placeholder token here\", interactive=True)\n",
        "                initializer_token = gr.Textbox(label=\"Initializer Token\", placeholder=\"Enter initializer token here\", interactive=True)\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\", placeholder=\"Enter your prompt here\", interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps\", value=100, interactive=True)\n",
        "                learning_rate = gr.Number(label=\"Learning Rate\", value=0.001, interactive=True)\n",
        "                batch_size = gr.Number(label=\"Batch Size\", value=1, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview/Save Every N Steps\", value=10, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "        generate_button = gr.Button(\"Start Training\")\n",
        "\n",
        "        generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[dataset_path, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                    learning_rate, batch_size, preview_save_steps, preview_seed],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "demo = ui()\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp4gds97p4b1",
        "outputId": "3b4df099-611e-4f2b-bcc6-8148d9f52465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "demo.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "diffusion",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
