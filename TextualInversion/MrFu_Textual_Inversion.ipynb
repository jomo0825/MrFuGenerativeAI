{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2l1NrzIPzuK",
        "outputId": "4de5c5c1-6a39-4449-8777-e8f1e00b10a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPackage installation finished.\n"
          ]
        }
      ],
      "source": [
        "# 1. Install the required packages\n",
        "# On Windows, you just need to execute this cell for once.\n",
        "try:\n",
        "    import google.colab\n",
        "    # IN_COLAB = True\n",
        "except ImportError:\n",
        "    # IN_COLAB = False\n",
        "    %pip install -q git+https://github.com/huggingface/transformers\n",
        "    %pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "%pip install -q git+https://github.com/huggingface/diffusers\n",
        "%pip install -q gradio ftfy tensorboard\n",
        "%pip install -q bitsandbytes\n",
        "#%pip install -U git+https://github.com/TimDettmers/bitsandbytes.git\n",
        "%pip install -q xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "#%pip install -U git+https://github.com/facebookresearch/xformers.git@main\n",
        "print(\"Package installation finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gVoVoNmnsrN",
        "outputId": "96ca34b3-e37e-4943-f910-87555a16e23e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "textual_inversion.py already exists, skipping download.\n"
          ]
        }
      ],
      "source": [
        "# 2. Create folders and download training scripts\n",
        "import os, shutil\n",
        "\n",
        "dataset_dir = \"./dataset\"\n",
        "output_dir = \"./output\"\n",
        "logging_dir = \"./logs\"\n",
        "\n",
        "available_models = {\n",
        "    \"SD v1.5\": \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "    \"SDXL\": \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "}\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "# Delete the 'output' folder and its contents\n",
        "shutil.rmtree(output_dir, ignore_errors=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "# Delete the 'log' folder and its contents\n",
        "shutil.rmtree(logging_dir, ignore_errors=True)\n",
        "os.makedirs(logging_dir, exist_ok=True)\n",
        "# Delete the 'dataset' folder and its contents\n",
        "# shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "# os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# fetch textual inversion code if it doesn't exist\n",
        "if not os.path.exists(\"textual_inversion.py\"):\n",
        "    !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/TextualInversion/textual_inversion.py\n",
        "else:\n",
        "    print(\"textual_inversion.py already exists, skipping download.\")\n",
        "\n",
        "if not os.path.exists(\"textual_inversion_sdxl.py\"):\n",
        "    !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/TextualInversion/textual_inversion_sdxl.py\n",
        "else:\n",
        "    print(\"textual_inversion_sdxl.py already exists, skipping download.\")\n",
        "\n",
        "ipynb_checkpoints = os.path.join( dataset_dir, \".ipynb_checkpoints\")\n",
        "shutil.rmtree(\".gradio\", ignore_errors=True)\n",
        "shutil.rmtree(\".config\", ignore_errors=True)\n",
        "shutil.rmtree(ipynb_checkpoints, ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "i7luCZ7oRmLI",
        "outputId": "406eebea-f245-4853-affd-ed350c9a8859"
      },
      "outputs": [],
      "source": [
        "# 3. Upload dataset images\n",
        "def load_dataset():\n",
        "  try:\n",
        "    from google.colab import files\n",
        "    import os\n",
        "\n",
        "    # Upload files from local machine\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move the uploaded files to the target directory\n",
        "    for filename in uploaded.keys():\n",
        "        # Get source and destination paths\n",
        "        source_path = filename\n",
        "        destination_path = os.path.join(dataset_dir, filename)\n",
        "\n",
        "        # Move the file\n",
        "        !mv \"{source_path}\" \"{destination_path}\"\n",
        "        print(f\"Moved {filename} to {dataset_dir}\")\n",
        "\n",
        "  except ImportError:\n",
        "    import tkinter as tk\n",
        "    from tkinter import filedialog\n",
        "    import os\n",
        "\n",
        "    # Initialize tkinter\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()  # Hide the root window\n",
        "    root.attributes('-topmost',True)\n",
        "\n",
        "    # Open a file dialog and allow multiple file selection\n",
        "    file_paths = filedialog.askopenfilenames(\n",
        "        title='Select Dataset Images',\n",
        "        filetypes=[('Image Files', '*.png;*.jpg;*.jpeg;*.bmp;*.gif')]\n",
        "    )\n",
        "    root.destroy()\n",
        "\n",
        "    # Define the target directory\n",
        "    target_directory = dataset_dir\n",
        "\n",
        "    # Copy or move files to the target directory\n",
        "    for file_path in file_paths:\n",
        "        filename = os.path.basename(file_path)\n",
        "        destination = os.path.join(target_directory, filename)\n",
        "        os.rename(file_path, destination)  # or use shutil.copy for copying\n",
        "        print(f'File {filename} saved to {target_directory}')\n",
        "\n",
        "load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "0wl0d-1HlRJZ",
        "outputId": "09011e11-e666-474a-9008-e7533d8c552f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from textual_inversion import main as train_textaul_inversion\n",
        "from textual_inversion import parse_args\n",
        "from textual_inversion_sdxl import main as train_textaul_inversion_sdxl\n",
        "from textual_inversion_sdxl import parse_args as parse_args_sdxl\n",
        "import threading, os, logging, time\n",
        "from os import path\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status, max_train_steps, current_step\n",
        "    current_step = step\n",
        "    current_preview = image\n",
        "    # current_status = f\"Preview updated at step {step}\"\n",
        "    # current_preview.show()\n",
        "    print(f\"{step}/{max_train_steps}\")\n",
        "\n",
        "\n",
        "def run_training(model_name, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                 learning_rate, batch_size, preview_save_steps, preview_seed):\n",
        "    global current_preview, current_status\n",
        "    global max_train_steps, current_step\n",
        "    current_preview = None  # Reset the preview\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "\n",
        "    # Construct the command with all arguments\n",
        "    command = [\n",
        "        # \"python\", \"textual_inversion.py\",\n",
        "        \"--pretrained_model_name_or_path\", available_models[model_name],\n",
        "        \"--train_data_dir\", dataset_dir,\n",
        "        \"--placeholder_token\", placeholder_token,\n",
        "        \"--initializer_token\", initializer_token,\n",
        "        \"--resolution\", str(1024 if model_name == \"SDXL\" else 512),\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--gradient_accumulation_steps\", \"1\",\n",
        "        \"--learning_rate\", str(learning_rate),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--save_steps\", str(preview_save_steps),\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--output_dir\", output_dir,\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--learnable_property\", \"object\",\n",
        "        \"--seed\", str(preview_seed),\n",
        "        \"--mixed_precision\", \"fp16\"\n",
        "    ]\n",
        "\n",
        "    # Print the command for debugging\n",
        "    # print(\"Command:\", \" \".join(command))\n",
        "\n",
        "    # Create the directories if they don't exist\n",
        "    os.makedirs(logging_dir, exist_ok=True)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Disable logging\n",
        "    # logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    # Run the command in a separate process\n",
        "    # process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Run the command as function\n",
        "    if model_name == \"SDXL\":\n",
        "        args = parse_args_sdxl(command)\n",
        "    else:\n",
        "        args = parse_args(command)        \n",
        "    max_train_steps = args.max_train_steps\n",
        "\n",
        "    def worker(finish_event):\n",
        "        try:\n",
        "            if model_name == \"SDXL\":\n",
        "                train_textaul_inversion(args, {\"_callback\": preview_callback})\n",
        "            else:\n",
        "                train_textaul_inversion_sdxl(args, {\"_callback\": preview_callback})                \n",
        "        except Exception as e:\n",
        "            print(f\"Training error: {e}\")\n",
        "        finally:\n",
        "            finish_event.set()\n",
        "\n",
        "    finish_event = threading.Event()\n",
        "    finish_event.clear()\n",
        "    # try:\n",
        "    train_thread = threading.Thread(target=worker, args=(finish_event,))\n",
        "    train_thread.start()\n",
        "    yield gr.update(value=None), gr.update(value=f\"Training started.\")\n",
        "\n",
        "    # except Exception as e:\n",
        "    #   print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "    while not finish_event.is_set():\n",
        "        if current_preview is not None:\n",
        "            yield gr.update(value=current_preview), gr.update(value=f\"Preview at {current_step} step.\")\n",
        "            current_preview = None\n",
        "        time.sleep(1)\n",
        "\n",
        "    train_thread.join()\n",
        "\n",
        "    # Print the output and errors (for debugging)\n",
        "    # print(\"Output:\", stdout.decode())\n",
        "    # print(\"Errors:\", stderr.decode())\n",
        "\n",
        "    # Update status when training completes\n",
        "    current_status = \"Training completed!\"\n",
        "\n",
        "    yield gr.update(), gr.update(value=current_status)\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion Textual Inversion UI\")\n",
        "        gr.Markdown(\"Generate images using a preloaded textual inversion model.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            model_name = gr.Dropdown(\n",
        "                label=\"Model Name\",\n",
        "                choices=available_models.keys(),\n",
        "                value= list(available_models.keys())[0] if available_models.keys() else \"Select a Model\",\n",
        "                interactive=True\n",
        "            )\n",
        "        \n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                placeholder_token = gr.Textbox(label=\"Placeholder Token\", placeholder=\"Enter placeholder token here\", interactive=True)\n",
        "                initializer_token = gr.Textbox(label=\"Initializer Token\", placeholder=\"Enter initializer token here\", interactive=True)\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\", placeholder=\"Enter your prompt here\", interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps\", value=100, interactive=True)\n",
        "                learning_rate = gr.Number(label=\"Learning Rate\", value=0.001, interactive=True)\n",
        "                batch_size = gr.Number(label=\"Batch Size\", value=4, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview/Save Every N Steps\", value=10, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "                generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "                generate_button = gr.Button(\"Start Training\")\n",
        "\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[model_name, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                    learning_rate, batch_size, preview_save_steps, preview_seed],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "demo = ui()\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pp4gds97p4b1",
        "outputId": "7f992232-3980-45bd-82d1-a2556f1c8fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7865\n"
          ]
        }
      ],
      "source": [
        "demo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLNzRswKkN9h",
        "outputId": "0d0cc3f8-7fe4-4ffe-d4e8-bda7ed060b1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'textual_inversion' from '/content/textual_inversion.py'>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "importlib.reload(textual_inversion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "HeS2aJ1fTFk4",
        "outputId": "493807d9-8bb6-4b07-e90d-f3d0234937b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--save_steps SAVE_STEPS] [--save_as_full_pipeline]\n",
            "                                [--num_vectors NUM_VECTORS] --pretrained_model_name_or_path\n",
            "                                PRETRAINED_MODEL_NAME_OR_PATH [--revision REVISION]\n",
            "                                [--variant VARIANT] [--tokenizer_name TOKENIZER_NAME]\n",
            "                                --train_data_dir TRAIN_DATA_DIR --placeholder_token\n",
            "                                PLACEHOLDER_TOKEN --initializer_token INITIALIZER_TOKEN\n",
            "                                [--learnable_property LEARNABLE_PROPERTY] [--repeats REPEATS]\n",
            "                                [--output_dir OUTPUT_DIR] [--seed SEED] [--resolution RESOLUTION]\n",
            "                                [--center_crop] [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "                                [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                                [--max_train_steps MAX_TRAIN_STEPS]\n",
            "                                [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                                [--gradient_checkpointing] [--learning_rate LEARNING_RATE]\n",
            "                                [--scale_lr] [--lr_scheduler LR_SCHEDULER]\n",
            "                                [--lr_warmup_steps LR_WARMUP_STEPS]\n",
            "                                [--lr_num_cycles LR_NUM_CYCLES]\n",
            "                                [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
            "                                [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
            "                                [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
            "                                [--adam_epsilon ADAM_EPSILON] [--push_to_hub]\n",
            "                                [--hub_token HUB_TOKEN] [--hub_model_id HUB_MODEL_ID]\n",
            "                                [--logging_dir LOGGING_DIR] [--mixed_precision {no,fp16,bf16}]\n",
            "                                [--allow_tf32] [--report_to REPORT_TO]\n",
            "                                [--validation_prompt VALIDATION_PROMPT]\n",
            "                                [--num_validation_images NUM_VALIDATION_IMAGES]\n",
            "                                [--validation_steps VALIDATION_STEPS]\n",
            "                                [--validation_epochs VALIDATION_EPOCHS] [--local_rank LOCAL_RANK]\n",
            "                                [--checkpointing_steps CHECKPOINTING_STEPS]\n",
            "                                [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
            "                                [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
            "                                [--enable_xformers_memory_efficient_attention]\n",
            "                                [--no_safe_serialization] [--test TEST]\n",
            "colab_kernel_launcher.py: error: the following arguments are required: --pretrained_model_name_or_path, --train_data_dir, --placeholder_token, --initializer_token\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "2",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "# import argparse\n",
        "\n",
        "# Create parser\n",
        "# parser = argparse.ArgumentParser(description='Your script description')\n",
        "# parser.add_argument('--seed', type=int, help='Argument 1')\n",
        "# parser.add_argument('--arg2', type=str, help='Argument 2')\n",
        "\n",
        "# Create fake args list and parse directly\n",
        "command2 = [\n",
        "        # \"python\", \"textual_inversion.py\",\n",
        "        # \"--pretrained_model_name_or_path\", \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "        # \"--train_data_dir\", dataset_dir,\n",
        "        # \"--placeholder_token\", placeholder_token,\n",
        "        # \"--initializer_token\", initializer_token,\n",
        "        # \"--resolution\", 512,\n",
        "        # \"--train_batch_size\", batch_size,\n",
        "        # \"--gradient_accumulation_steps\", 1,\n",
        "        # \"--learning_rate\", learning_rate,\n",
        "        # \"--max_train_steps\", num_training_steps,\n",
        "        # \"--save_steps\", preview_save_steps,\n",
        "        # \"--validation_steps\", preview_save_steps,\n",
        "        # \"--output_dir\", output_dir,\n",
        "        # \"--logging_dir\", logging_dir,\n",
        "        # \"--validation_prompt\", prompt,\n",
        "        # \"--learnable_property\", \"object\",\n",
        "        \"--seed\", str(1)\n",
        "]\n",
        "\n",
        "args2 = parse_args(command2)\n",
        "print(args2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "diffusion",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
