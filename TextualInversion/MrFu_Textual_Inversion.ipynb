{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2l1NrzIPzuK"
      },
      "outputs": [],
      "source": [
        "# 1. Install the required packages\n",
        "# On Windows, you just need to execute this cell for once.\n",
        "try:\n",
        "    import google.colab\n",
        "    # IN_COLAB = True\n",
        "except ImportError:\n",
        "    # IN_COLAB = False\n",
        "    %pip install -q git+https://github.com/huggingface/transformers\n",
        "    %pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "%pip install -q git+https://github.com/huggingface/diffusers\n",
        "%pip install -q gradio ftfy tensorboard\n",
        "%pip install -q bitsandbytes\n",
        "#%pip install -U git+https://github.com/TimDettmers/bitsandbytes.git\n",
        "%pip install -q xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "#%pip install -U git+https://github.com/facebookresearch/xformers.git@main\n",
        "print(\"Package installation finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gVoVoNmnsrN"
      },
      "outputs": [],
      "source": [
        "# 2. Create folders and download training scripts\n",
        "import os, shutil\n",
        "\n",
        "dataset_dir = \"./dataset\"\n",
        "output_dir = \"./output\"\n",
        "logging_dir = \"./logs\"\n",
        "\n",
        "available_models = {\n",
        "    \"SD v1.5\": \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "    # \"SDXL\": \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "}\n",
        "\n",
        "def reset_data():\n",
        "  # Create the directories if they don't exist\n",
        "  os.makedirs(dataset_dir, exist_ok=True)\n",
        "  # Delete the 'output' folder and its contents\n",
        "  shutil.rmtree(output_dir, ignore_errors=True)\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "  # Delete the 'log' folder and its contents\n",
        "  shutil.rmtree(logging_dir, ignore_errors=True)\n",
        "  os.makedirs(logging_dir, exist_ok=True)\n",
        "  # Delete the 'dataset' folder and its contents\n",
        "  # shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "  # os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "  # fetch textual inversion code if it doesn't exist\n",
        "  if not os.path.exists(\"textual_inversion.py\"):\n",
        "      !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/TextualInversion/textual_inversion.py\n",
        "  else:\n",
        "      print(\"textual_inversion.py already exists, skipping download.\")\n",
        "\n",
        "  ipynb_checkpoints = os.path.join( dataset_dir, \".ipynb_checkpoints\")\n",
        "  shutil.rmtree(\".gradio\", ignore_errors=True)\n",
        "  shutil.rmtree(\".config\", ignore_errors=True)\n",
        "  shutil.rmtree(ipynb_checkpoints, ignore_errors=True)\n",
        "\n",
        "reset_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7luCZ7oRmLI"
      },
      "outputs": [],
      "source": [
        "# 3. Upload dataset images\n",
        "def load_dataset():\n",
        "  try:\n",
        "    from google.colab import files\n",
        "    import os\n",
        "\n",
        "    # Upload files from local machine\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move the uploaded files to the target directory\n",
        "    for filename in uploaded.keys():\n",
        "        # Get source and destination paths\n",
        "        source_path = filename\n",
        "        destination_path = os.path.join(dataset_dir, filename)\n",
        "\n",
        "        # Move the file\n",
        "        !mv \"{source_path}\" \"{destination_path}\"\n",
        "        print(f\"Moved {filename} to {dataset_dir}\")\n",
        "\n",
        "  except ImportError:\n",
        "    import tkinter as tk\n",
        "    from tkinter import filedialog\n",
        "    import os\n",
        "\n",
        "    # Initialize tkinter\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()  # Hide the root window\n",
        "    root.attributes('-topmost',True)\n",
        "\n",
        "    # Open a file dialog and allow multiple file selection\n",
        "    file_paths = filedialog.askopenfilenames(\n",
        "        title='Select Dataset Images',\n",
        "        filetypes=[('Image Files', '*.png;*.jpg;*.jpeg;*.bmp;*.gif')]\n",
        "    )\n",
        "    root.destroy()\n",
        "\n",
        "    # Define the target directory\n",
        "    target_directory = dataset_dir\n",
        "\n",
        "    # Copy or move files to the target directory\n",
        "    for file_path in file_paths:\n",
        "        filename = os.path.basename(file_path)\n",
        "        destination = os.path.join(target_directory, filename)\n",
        "        os.rename(file_path, destination)  # or use shutil.copy for copying\n",
        "        print(f'File {filename} saved to {target_directory}')\n",
        "\n",
        "load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wl0d-1HlRJZ"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from textual_inversion import main as train_textual_inversion\n",
        "from textual_inversion import parse_args\n",
        "# from textual_inversion_sdxl import main as train_textaul_inversion_sdxl\n",
        "# from textual_inversion_sdxl import parse_args as parse_args_sdxl\n",
        "import threading, os, logging, time\n",
        "from os import path\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status, max_train_steps, current_step\n",
        "    current_step = step\n",
        "    current_preview = image\n",
        "    # current_status = f\"Preview updated at step {step}\"\n",
        "    # current_preview.show()\n",
        "    print(f\"{step}/{max_train_steps}\")\n",
        "\n",
        "def stop_training():\n",
        "  global stop_flag\n",
        "  stop_flag.set()\n",
        "  return gr.update(value=\"Training stopped.\")\n",
        "\n",
        "def run_training(model_name, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                 learning_rate, batch_size, preview_save_steps, preview_seed):\n",
        "    global current_preview, current_status\n",
        "    global max_train_steps, current_step, finish_event, stop_flag\n",
        "    current_preview = None  # Reset the preview\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "\n",
        "    # Construct the command with all arguments\n",
        "    command = [\n",
        "        # \"python\", \"textual_inversion.py\",\n",
        "        \"--pretrained_model_name_or_path\", available_models[model_name],\n",
        "        \"--train_data_dir\", dataset_dir,\n",
        "        \"--placeholder_token\", placeholder_token,\n",
        "        \"--initializer_token\", initializer_token,\n",
        "        \"--resolution\", str(512),\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--gradient_accumulation_steps\", \"1\",\n",
        "        \"--learning_rate\", str(learning_rate),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--save_steps\", str(preview_save_steps),\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--output_dir\", output_dir,\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--learnable_property\", \"object\",\n",
        "        \"--seed\", str(preview_seed),\n",
        "        \"--mixed_precision\", \"fp16\",\n",
        "        \"--enable_xformers_memory_efficient_attention\"\n",
        "    ]\n",
        "\n",
        "    # Print the command for debugging\n",
        "    # print(\"Command:\", \" \".join(command))\n",
        "\n",
        "    # Create the directories if they don't exist\n",
        "    # os.makedirs(logging_dir, exist_ok=True)\n",
        "    # os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Disable logging\n",
        "    # logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    # Run the command in a separate process\n",
        "    # process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Run the command as function\n",
        "    # if model_name == \"SDXL\":\n",
        "    #     args = parse_args_sdxl(command)\n",
        "    # else:\n",
        "    args = parse_args(command)\n",
        "\n",
        "    yield gr.update(value=None), gr.update(value=\" \".join(command))\n",
        "\n",
        "    max_train_steps = args.max_train_steps\n",
        "\n",
        "    def worker(finish_event, stop_flag):\n",
        "      try:\n",
        "        train_textual_inversion(args, {\"_callback\": preview_callback, \"stop_flag\": stop_flag})\n",
        "      except Exception as e:\n",
        "        print(f\"Training error: {e}\")\n",
        "      finally:\n",
        "        finish_event.set()\n",
        "\n",
        "    finish_event = threading.Event()\n",
        "    stop_flag = threading.Event()\n",
        "    finish_event.clear()\n",
        "    stop_flag.clear()\n",
        "\n",
        "    train_thread = threading.Thread(target=worker, args=(finish_event, stop_flag))\n",
        "    train_thread.start()\n",
        "    yield gr.update(value=None), gr.update(value=f\"Training started.\")\n",
        "\n",
        "    # except Exception as e:\n",
        "    #   print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "    while not finish_event.is_set():\n",
        "        if current_preview is not None:\n",
        "            yield gr.update(value=current_preview), gr.update(value=f\"Preview at {current_step} step.\")\n",
        "            current_preview = None\n",
        "        time.sleep(1)\n",
        "\n",
        "    train_thread.join()\n",
        "\n",
        "    # Print the output and errors (for debugging)\n",
        "    # print(\"Output:\", stdout.decode())\n",
        "    # print(\"Errors:\", stderr.decode())\n",
        "\n",
        "    # Update status when training completes\n",
        "    current_status = \"Training completed!\"\n",
        "\n",
        "    yield gr.update(), gr.update(value=current_status)\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion Textual Inversion UI\")\n",
        "        gr.Markdown(\"Generate images using a preloaded textual inversion model.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            model_name = gr.Dropdown(\n",
        "                label=\"Model Name\",\n",
        "                choices=available_models.keys(),\n",
        "                value= list(available_models.keys())[0] if available_models.keys() else \"Select a Model\",\n",
        "                interactive=True\n",
        "            )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                placeholder_token = gr.Textbox(label=\"Placeholder Token\", value=\"\", placeholder=\"Enter placeholder token here\", interactive=True)\n",
        "                initializer_token = gr.Textbox(label=\"Initializer Token\", value=\"\", placeholder=\"Enter initializer token here\", interactive=True)\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\", value=\"\", placeholder=\"Enter your prompt here\", interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps\", value=1000, interactive=True)\n",
        "                learning_rate = gr.Number(label=\"Learning Rate\", value=0.001, interactive=True)\n",
        "                batch_size = gr.Number(label=\"Batch Size\", value=1, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview/Save Every N Steps\", value=10, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "                generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "                generate_button = gr.Button(\"Start Training\")\n",
        "                cancel_button = gr.Button(\"Cancel Training\")\n",
        "                reset_button = gr.Button(\"Reset Data\")\n",
        "\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[model_name, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                    learning_rate, batch_size, preview_save_steps, preview_seed],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "        cancel_button.click(\n",
        "            fn=stop_training,\n",
        "            outputs=[generate_status]\n",
        "        )\n",
        "\n",
        "        reset_button.click(\n",
        "            fn=reset_data\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "demo = ui()\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp4gds97p4b1"
      },
      "outputs": [],
      "source": [
        "demo.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}