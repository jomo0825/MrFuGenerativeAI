{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2l1NrzIPzuK"
      },
      "outputs": [],
      "source": [
        "# 1. Install the required packages\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "print(\"Package installation finished.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gVoVoNmnsrN",
        "outputId": "95d1c18d-332c-47c1-e95a-7a361e3f1e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "textual_inversion.py already exists, skipping download.\n"
          ]
        }
      ],
      "source": [
        "# 2. Create folders and download training scripts\n",
        "import os, shutil\n",
        "\n",
        "#global variables\n",
        "dataset_dir = \"./dataset\"\n",
        "output_dir = \"./output\"\n",
        "logging_dir = \"./logs\"\n",
        "\n",
        "token_name = \"\"\n",
        "pipeline = None\n",
        "\n",
        "available_models = {\n",
        "    \"SD v1.5\": \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "    # \"SDXL\": \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "}\n",
        "\n",
        "def reset_data():\n",
        "    # Create the directories if they don't exist\n",
        "    # shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "    # Delete the 'output' folder and its contents\n",
        "    shutil.rmtree(output_dir, ignore_errors=True)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir,\"images\"), exist_ok=True)\n",
        "    # Delete the 'log' folder and its contents\n",
        "    shutil.rmtree(logging_dir, ignore_errors=True)\n",
        "    os.makedirs(logging_dir, exist_ok=True)\n",
        "    # Delete the 'dataset' folder and its contents\n",
        "    # shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "    # os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "    # fetch textual inversion code if it doesn't exist\n",
        "    if not os.path.exists(\"textual_inversion.py\"):\n",
        "        !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/TextualInversion/textual_inversion.py\n",
        "    else:\n",
        "        print(\"textual_inversion.py already exists, skipping download.\")\n",
        "\n",
        "    ipynb_checkpoints = os.path.join( dataset_dir, \".ipynb_checkpoints\")\n",
        "    shutil.rmtree(\".gradio\", ignore_errors=True)\n",
        "    shutil.rmtree(\".config\", ignore_errors=True)\n",
        "    shutil.rmtree(ipynb_checkpoints, ignore_errors=True)\n",
        "\n",
        "reset_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wl0d-1HlRJZ",
        "outputId": "4c28d84e-49c6-4067-941d-6d6ce3b0468e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A matching Triton is not available, some optimizations will not be enabled\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\n",
            "    import triton  # noqa\n",
            "ModuleNotFoundError: No module named 'triton'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3. Open WebUI\n",
        "import gradio as gr\n",
        "from textual_inversion import main as train_textual_inversion\n",
        "from textual_inversion import parse_args\n",
        "# from textual_inversion_sdxl import main as train_textaul_inversion_sdxl\n",
        "# from textual_inversion_sdxl import parse_args as parse_args_sdxl\n",
        "import threading, os, logging, time\n",
        "from os import path\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "# def preview_callback(image, step):\n",
        "#     global current_preview, current_status, max_train_steps, current_step\n",
        "#     current_step = step\n",
        "#     current_preview = image\n",
        "#     # current_status = f\"Preview updated at step {step}\"\n",
        "#     # current_preview.show()\n",
        "#     print(f\"{step}/{max_train_steps}\")\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status, max_train_steps, current_step\n",
        "    current_step = step\n",
        "    if image is not None:\n",
        "        current_preview = image\n",
        "        image.save(os.path.join(output_dir, \"images\", f\"image_{step}.png\"))\n",
        "\n",
        "def stop_training():\n",
        "  global stop_flag\n",
        "  stop_flag.set()\n",
        "  return gr.update(value=\"Training will be stopped...Waiting for the final preview...\")\n",
        "\n",
        "def run_training(model_name, prompt, placeholder_token, initializer_token, concept_type, num_training_steps,\n",
        "                 learning_rate, batch_size, acc_steps, preview_save_steps, preview_seed):\n",
        "    global current_preview, current_status, token_name, pipeline\n",
        "    global max_train_steps, current_step, finish_event, stop_flag\n",
        "    current_preview = None  # Reset the preview\n",
        "    token_name = placeholder_token\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "    pipeline = None\n",
        "\n",
        "    # Construct the command with all arguments\n",
        "    command = [\n",
        "        # \"python\", \"textual_inversion.py\",\n",
        "        \"--pretrained_model_name_or_path\", available_models[model_name],\n",
        "        \"--train_data_dir\", dataset_dir,\n",
        "        \"--placeholder_token\", placeholder_token,\n",
        "        \"--initializer_token\", initializer_token,\n",
        "        \"--resolution\", str(512),\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--gradient_accumulation_steps\", str(acc_steps),\n",
        "        \"--learning_rate\", str(learning_rate),\n",
        "        \"--lr_scheduler\", str(\"cosine\"),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--save_steps\", str(preview_save_steps),\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--output_dir\", output_dir,\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--learnable_property\", concept_type,\n",
        "        \"--seed\", str(preview_seed),\n",
        "        \"--mixed_precision\", \"fp16\",\n",
        "        # \"--enable_xformers_memory_efficient_attention\",\n",
        "    ]\n",
        "\n",
        "    # Print the command for debugging\n",
        "    # print(\"Command:\", \" \".join(command))\n",
        "    # Disable logging\n",
        "    logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    args = parse_args(command)\n",
        "\n",
        "    # yield gr.update(value=None), gr.update(value=\" \".join(command))\n",
        "\n",
        "    max_train_steps = args.max_train_steps\n",
        "\n",
        "    def worker(finish_event, stop_flag):\n",
        "      try:\n",
        "        train_textual_inversion(args, {\"_callback\": preview_callback, \"stop_flag\": stop_flag})\n",
        "      except Exception as e:\n",
        "        print(f\"Training error: {e}\")\n",
        "      finally:\n",
        "        finish_event.set()\n",
        "\n",
        "    finish_event = threading.Event()\n",
        "    stop_flag = threading.Event()\n",
        "    finish_event.clear()\n",
        "    stop_flag.clear()\n",
        "\n",
        "    train_thread = threading.Thread(target=worker, args=(finish_event, stop_flag))\n",
        "    train_thread.start()\n",
        "    yield gr.update(value=None), gr.update(value=f\"Training started.\")\n",
        "\n",
        "    # except Exception as e:\n",
        "    #   print(f\"Error: {e}\")\n",
        "\n",
        "    current_step = None\n",
        "    while not finish_event.is_set():\n",
        "        if current_step is not None:\n",
        "            yield gr.update(value=current_preview), gr.update(value=f\"Trainng on {current_step} step.\")\n",
        "            current_step = None\n",
        "        time.sleep(1)\n",
        "\n",
        "    train_thread.join()\n",
        "\n",
        "    # Print the output and errors (for debugging)\n",
        "    # print(\"Output:\", stdout.decode())\n",
        "    # print(\"Errors:\", stderr.decode())\n",
        "\n",
        "    # Update status when training completes\n",
        "    current_status = \"Training completed!\"\n",
        "\n",
        "    yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "\n",
        "\n",
        "# Define a function to move the selected file\n",
        "def copy_file(target_directory, file_path):\n",
        "  if file_path is not None:\n",
        "      filename = os.path.basename(file_path)\n",
        "      destination_path = os.path.join(target_directory, filename)\n",
        "      # test if the destination_path alread exist\n",
        "      if not os.path.exists(destination_path):\n",
        "        shutil.copy(file_path, destination_path)\n",
        "        print(f\"Copy {filename} to {target_directory}\")\n",
        "      else:\n",
        "        print(f\"{filename} already exists.\")\n",
        "  else:\n",
        "      print(\"No file selected.\")\n",
        "\n",
        "def process_files(files):\n",
        "    file_info = []\n",
        "\n",
        "    for file in files:\n",
        "        fileBasename = os.path.basename(file)\n",
        "        destination_path = os.path.join(dataset_dir, fileBasename)\n",
        "        if not os.path.exists(destination_path):\n",
        "            file_info.append(f\"File: {file.name}\")\n",
        "            copy_file(dataset_dir, file.name )\n",
        "    return f\"{len(file_info)} files uploaded.\"\n",
        "\n",
        "def delete_dataset():\n",
        "  shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "  os.makedirs(dataset_dir, exist_ok=True)\n",
        "  return \"Dataset deleted.\"\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion Textual Inversion UI\")\n",
        "        gr.Markdown(\"Generate images using a preloaded textual inversion model.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            model_name = gr.Dropdown(\n",
        "                label=\"Model Name\",\n",
        "                choices=available_models.keys(),\n",
        "                value= list(available_models.keys())[0] if available_models.keys() else \"Select a Model\",\n",
        "                interactive=True\n",
        "            )\n",
        "\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(file_count=\"multiple\", label=\"Upload Files\")\n",
        "        with gr.Row():\n",
        "            submit_btn = gr.Button(\"Upload Files\")\n",
        "            delete_data_btn = gr.Button(\"Delete Dataset\")\n",
        "        with gr.Row():\n",
        "            output = gr.Textbox(label=\"Results\")\n",
        "        submit_btn.click(fn=process_files, inputs=file_input, outputs=output)\n",
        "        delete_data_btn.click(fn=delete_dataset, outputs=output)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                placeholder_token = gr.Textbox(label=\"Placeholder Token\", value=\"\", placeholder=\"Enter placeholder token here\", interactive=True)\n",
        "                initializer_token = gr.Textbox(label=\"Initializer Token\", value=\"\", placeholder=\"Enter initializer token here\", interactive=True)\n",
        "                btn_group = gr.Radio([\"object\", \"style\"], value=\"object\", label=\"Concept Type\", interactive=True )\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\", value=\"\", placeholder=\"Enter your prompt here\", interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps\", value=1500, interactive=True)\n",
        "                learning_rate = gr.Number(label=\"Learning Rate\", value=0.001, interactive=True)\n",
        "                with gr.Row():\n",
        "                    batch_size = gr.Number(label=\"Batch Size\", value=2, interactive=True)\n",
        "                    acc_steps = gr.Number(label=\"Accumulate Steps\", value=1, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview/Save Every N Steps\", value=10, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "                generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "                generate_button = gr.Button(\"Start Training\")\n",
        "                cancel_button = gr.Button(\"Cancel Training\")\n",
        "                reset_button = gr.Button(\"Reset Data\")\n",
        "\n",
        "        concept_type = gr.State(\"\")\n",
        "\n",
        "        def process_selection(selected_value, stored_value):\n",
        "            # Here, we update the stored_value with the current selection.\n",
        "            stored_value = selected_value\n",
        "            return stored_value\n",
        "\n",
        "        btn_group.change(fn=process_selection, inputs=[btn_group, concept_type], outputs=concept_type)\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[model_name, prompt, placeholder_token, initializer_token, concept_type, num_training_steps,\n",
        "                    learning_rate, batch_size, acc_steps, preview_save_steps, preview_seed],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "        cancel_button.click(\n",
        "            fn=stop_training,\n",
        "            outputs=[generate_status]\n",
        "        )\n",
        "\n",
        "        reset_button.click(\n",
        "            fn=reset_data\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "demo = ui()\n",
        "# demo.launch(debug=True)\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp4gds97p4b1",
        "outputId": "9145af80-a118-4fe2-c55a-064b2fa19623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7861\n"
          ]
        }
      ],
      "source": [
        "demo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ac7308ac848e4726b2ae66bac60f518b"
          ]
        },
        "id": "SBEqouVvGsQM",
        "outputId": "65db9b83-6c5c-4279-daf2-d528bfc6f54f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac7308ac848e4726b2ae66bac60f518b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "OSError",
          "evalue": "We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like output\\.safetensors is not the path to a directory containing a file named learned_embeds.bin or \nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/diffusers/installation#offline-mode'.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32mc:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\diffusers\\utils\\hub_utils.py:289\u001b[0m, in \u001b[0;36m_get_model_file\u001b[1;34m(pretrained_model_name_or_path, weights_name, subfolder, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, dduf_entries)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# 2. Load model file as usual\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m     model_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_file\n",
            "File \u001b[1;32mc:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
            "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'output\\.safetensors'.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [3], line 14\u001b[0m\n\u001b[0;32m      8\u001b[0m     pipeline \u001b[38;5;241m=\u001b[39m StableDiffusionPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstable-diffusion-v1-5/stable-diffusion-v1-5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m         torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m     11\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39menable_xformers_memory_efficient_attention()\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_textual_inversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtoken_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.safetensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m scheduler_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariance_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pipeline\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mconfig:\n",
            "File \u001b[1;32mc:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\diffusers\\loaders\\textual_inversion.py:385\u001b[0m, in \u001b[0;36mTextualInversionLoaderMixin.load_textual_inversion\u001b[1;34m(self, pretrained_model_name_or_path, token, tokenizer, text_encoder, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_text_inv_inputs(tokenizer, text_encoder, pretrained_model_name_or_paths, tokens)\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# 4. Load state dicts of textual embeddings\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m state_dicts \u001b[38;5;241m=\u001b[39m load_textual_inversion_state_dicts(pretrained_model_name_or_paths, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# 4.1 Handle the special case when state_dict is a tensor that contains n embeddings for n tokens\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tokens) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(state_dicts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\diffusers\\loaders\\textual_inversion.py:89\u001b[0m, in \u001b[0;36mload_textual_inversion_state_dicts\u001b[1;34m(pretrained_model_name_or_paths, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m             model_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m         model_file \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTEXT_INVERSION_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m load_state_dict(model_file)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\diffusers\\utils\\hub_utils.py:325\u001b[0m, in \u001b[0;36m_get_model_file\u001b[1;34m(pretrained_model_name_or_path, weights_name, subfolder, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, dduf_entries)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    323\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load this model, couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the cached files and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not the path to a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m directory containing a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m offline mode at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/diffusers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load the model for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like output\\.safetensors is not the path to a directory containing a file named learned_embeds.bin or \nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/diffusers/installation#offline-mode'."
          ]
        }
      ],
      "source": [
        "# Option#1: Test the TI model\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
        "import torch\n",
        "import random\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "if pipeline is None:\n",
        "    pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "        \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "        torch_dtype=torch.float16,\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    pipeline.enable_xformers_memory_efficient_attention()\n",
        "    pipeline.load_textual_inversion(os.path.normpath(os.path.join(output_dir, f\"{token_name}.safetensors\")))\n",
        "\n",
        "scheduler_args = {}\n",
        "\n",
        "if \"variance_type\" in pipeline.scheduler.config:\n",
        "    variance_type = pipeline.scheduler.config.variance_type\n",
        "\n",
        "    if variance_type in [\"learned\", \"learned_range\"]:\n",
        "        variance_type = \"fixed_small\"\n",
        "\n",
        "    scheduler_args[\"variance_type\"] = variance_type\n",
        "\n",
        "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "\n",
        "random_number = random.randint(-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff)\n",
        "generator = torch.Generator().manual_seed(random_number)\n",
        "display(HTML(f\"Seed: 【<span style='color: yellow;'>{random_number}</span>】\"))\n",
        "\n",
        "preview_prompt =\"wpg\"\n",
        "negative_prompt = \"\"\n",
        "negative_prompt += \"disfigured, kitsch, ugly, oversaturated, grain, low-res, Deformed, blurry, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, poorly drawn hands, missing limb, blurry, floating limbs, disconnected limbs, malformed hands, blur, out of focus, long neck, long body, disgusting, poorly drawn, childish, mutilated, mangled, old, surreal\"\n",
        "\n",
        "output = pipeline(\n",
        "    preview_prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=20,\n",
        "    guidance_scale=7,\n",
        ")\n",
        "\n",
        "display(output.images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGHQoyANX7aP"
      },
      "outputs": [],
      "source": [
        "# 4. Download your model\n",
        "# If you are using Colab, you can mount Google Drive and upload your model in .safetensors format\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Create a directory in Google Drive if it doesn't exist\n",
        "    import os\n",
        "    target_dir = \"/content/drive/MyDrive/TextualInversion\"\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "        print(f\"Created directory: {target_dir}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {target_dir}\")\n",
        "\n",
        "    # Copy your file to Drive\n",
        "    !cp /content/{output_dir}/{token_name}.safetensors {target_dir}/{token_name}.safetensors\n",
        "    print(f\"Your Textual Inversion model has been uploaded to your Google Drive folder {target_dir}\")\n",
        "except:\n",
        "  pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "diffusion",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
