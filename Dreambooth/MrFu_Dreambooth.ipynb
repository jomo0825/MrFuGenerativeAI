{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBByDHe3Su6a"
      },
      "outputs": [],
      "source": [
        "# 1. Install the required packages\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "print(\"Package installation finished.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gVoVoNmnsrN"
      },
      "outputs": [],
      "source": [
        "# 2. Create folders and download training scripts\n",
        "import os, shutil\n",
        "\n",
        "dataset_dir = \"./dataset\"\n",
        "output_dir = \"./output\"\n",
        "logging_dir = \"./logs\"\n",
        "class_dir = \"./class\"\n",
        "base_model=\"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
        "\n",
        "token_name = \"sks\"\n",
        "pipeline = None\n",
        "\n",
        "def reset_data():\n",
        "  # Create the directories if they don't exist\n",
        "  os.makedirs(dataset_dir, exist_ok=True)\n",
        "  # Delete the 'output' folder and its contents\n",
        "  shutil.rmtree(output_dir, ignore_errors=True)\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "  os.makedirs(os.path.join(output_dir, \"images\" ), exist_ok=True)\n",
        "  # Delete the 'log' folder and its contents\n",
        "  shutil.rmtree(logging_dir, ignore_errors=True)\n",
        "  os.makedirs(logging_dir, exist_ok=True)\n",
        "  # Delete the 'class' folder and its contents\n",
        "  # shutil.rmtree(class_dir, ignore_errors=True)\n",
        "  os.makedirs(class_dir, exist_ok=True)\n",
        "  # Delete the 'dataset' folder and its contents\n",
        "  # shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "  # os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "  # fetch train_dreambooth.py if it doesn't exist\n",
        "  if not os.path.exists(\"train_dreambooth.py\"):\n",
        "      !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/Dreambooth/train_dreambooth.py\n",
        "  else:\n",
        "      print(\"train_dreambooth.py already exists, skipping download.\")\n",
        "\n",
        "  # fetch convertosdv2.py if it doesn't exist\n",
        "  if not os.path.exists(\"convert_diffusers_to_original_stable_diffusion.py\"):\n",
        "      !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/utils/convert_diffusers_to_original_stable_diffusion.py\n",
        "  else:\n",
        "      print(\"convert_diffusers_to_original_stable_diffusion.py already exists, skipping download.\")\n",
        "\n",
        "  ipynb_checkpoints = os.path.join( dataset_dir, \".ipynb_checkpoints\")\n",
        "  shutil.rmtree(\".gradio\", ignore_errors=True)\n",
        "  shutil.rmtree(\".config\", ignore_errors=True)\n",
        "  shutil.rmtree(ipynb_checkpoints, ignore_errors=True)\n",
        "\n",
        "reset_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wl0d-1HlRJZ"
      },
      "outputs": [],
      "source": [
        "# 3. Create a WebUI for training\n",
        "# It will download the SD v1.5 for the 1st time training\n",
        "# A very good reference:\n",
        "# https://www.reddit.com/r/StableDiffusion/comments/ybxv7h/good_dreambooth_formula/\n",
        "import importlib\n",
        "import train_dreambooth\n",
        "\n",
        "# Force reload\n",
        "importlib.reload(train_dreambooth)\n",
        "\n",
        "import gradio as gr\n",
        "import sys\n",
        "import threading\n",
        "from train_dreambooth import main as train_dreambooth\n",
        "from train_dreambooth import parse_args\n",
        "import time, os, logging\n",
        "from os import path\n",
        "import subprocess\n",
        "import shlex\n",
        "import queue\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status, max_train_steps, current_step\n",
        "    current_step = step\n",
        "    if image is not None:\n",
        "        current_preview = image\n",
        "        image.save(os.path.join(output_dir, \"images\", f\"image_{step}.png\"))\n",
        "    # print(f\"{step}/{max_train_steps}\")\n",
        "\n",
        "def stop_training():\n",
        "  global stop_flag\n",
        "  stop_flag.set()\n",
        "  return gr.update(value=\"Training will be stopped...Waiting for the final preview...\")\n",
        "\n",
        "def run_training(prompt, placeholder_token, class_token, num_training_steps,\n",
        "                 learning_rate, batch_size, preview_save_steps, preview_seed):\n",
        "    global current_preview, current_status, max_train_steps, token_name\n",
        "    global current_step, finish_event, stop_flag, pipeline\n",
        "    current_preview = None  # Reset the preview\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "    token_name = placeholder_token\n",
        "    pipeline = None\n",
        "\n",
        "    # Define DreamBooth training parameters as a list of command-line arguments.\n",
        "    # Adjust the paths, prompts, and hyperparameters to match your experiment.\n",
        "    command = [\n",
        "        # \"accelerate\", \"launch\", \"train_dreambooth.py\",\n",
        "        \"--pretrained_model_name_or_path\", base_model,  # or your chosen model\n",
        "        \"--instance_data_dir\", dataset_dir,  # folder with your subject images\n",
        "        \"--instance_prompt\", placeholder_token,  # prompt identifier for your subject\n",
        "        \"--output_dir\", output_dir,          # where to save your DreamBooth model\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--resolution\", \"512\",\n",
        "        \"--lr_scheduler\", \"cosine\",\n",
        "        \"--learning_rate\", str(float(learning_rate)),\n",
        "        \"--lr_warmup_steps\", \"0\",\n",
        "        \"--gradient_accumulation_steps\", \"1\",\n",
        "        \"--num_validation_images\", \"1\",\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--mixed_precision\", \"fp16\",\n",
        "        \"--use_8bit_adam\",\n",
        "        \"--gradient_checkpointing\",\n",
        "        \"--enable_xformers_memory_efficient_attention\",\n",
        "        \"--set_grads_to_none\",\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--seed\", str(preview_seed),\n",
        "        \"--checkpointing_steps\", str(num_training_steps+1),\n",
        "\n",
        "        \"--class_data_dir\", class_dir,        # folder with class images (for prior preservation)\n",
        "        \"--class_prompt\", class_token,        # prompt for class images\n",
        "        \"--with_prior_preservation\",           # enable prior preservation if you have class images\n",
        "        \"--num_class_images\", \"10\",           # adjust based on your available class images\n",
        "        # Add other DreamBooth parameters as needed\n",
        "    ]\n",
        "\n",
        "    args = parse_args(command)\n",
        "    max_train_steps = args.max_train_steps\n",
        "\n",
        "    # Print the command for debugging\n",
        "    print(\"Command:\", \" \".join(command))\n",
        "\n",
        "    # Disable logging\n",
        "    logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    # Run the command in a separate process\n",
        "    # global process\n",
        "    # process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    def worker(finish_event, stop_flag):\n",
        "      try:\n",
        "        train_dreambooth(args, {\"_callback\": preview_callback, \"stop_flag\": stop_flag})\n",
        "      except Exception as e:\n",
        "        print(f\"Training error: {e}\")\n",
        "      finally:\n",
        "        finish_event.set()\n",
        "\n",
        "    finish_event = threading.Event()\n",
        "    stop_flag = threading.Event()\n",
        "    finish_event.clear()\n",
        "    stop_flag.clear()\n",
        "\n",
        "    train_thread = threading.Thread(target=worker, args=(finish_event, stop_flag))\n",
        "    train_thread.start()\n",
        "    yield gr.update(value=None), gr.update(value=f\"Training started.\")\n",
        "    current_step = None\n",
        "    while not finish_event.is_set():\n",
        "        if current_preview is not None:\n",
        "            yield gr.update(value=current_preview), gr.update(value=f\"Preview at {current_step} step.\")\n",
        "            current_preview = None\n",
        "        time.sleep(1)\n",
        "\n",
        "    train_thread.join()\n",
        "\n",
        "    # Update status when training completes\n",
        "    # current_status = \"Converting model...\"\n",
        "    # yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "    # !python convert_diffusers_to_original_stable_diffusion.py --model_path {output_dir} --checkpoint_path model.safetensors --use_safetensors\n",
        "\n",
        "    current_status = \"Training completed! Remember to save model.safetensors in next cell#5.\"\n",
        "    # process.kill()\n",
        "    pipeline=None\n",
        "    yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "\n",
        "# Define a function to move the selected file\n",
        "def copy_file(target_directory, file_path):\n",
        "  if file_path is not None:\n",
        "      filename = os.path.basename(file_path)\n",
        "      destination_path = os.path.join(target_directory, filename)\n",
        "      # test if the destination_path alread exist\n",
        "      if not os.path.exists(destination_path):\n",
        "        shutil.copy(file_path, destination_path)\n",
        "        print(f\"Copy {filename} to {target_directory}\")\n",
        "      else:\n",
        "        print(f\"{filename} already exists.\")\n",
        "  else:\n",
        "      print(\"No file selected.\")\n",
        "\n",
        "def process_files(files):\n",
        "    file_info = []\n",
        "\n",
        "    for file in files:\n",
        "        fileBasename = os.path.basename(file)\n",
        "        destination_path = os.path.join(dataset_dir, fileBasename)\n",
        "        if not os.path.exists(destination_path):\n",
        "            file_info.append(f\"File: {file.name}\")\n",
        "            copy_file(dataset_dir, file.name )\n",
        "    return f\"{len(file_info)} files uploaded.\"\n",
        "\n",
        "def process_class_files(files):\n",
        "    file_info = []\n",
        "\n",
        "    for file in files:\n",
        "        fileBasename = os.path.basename(file)\n",
        "        destination_path = os.path.join(class_dir, fileBasename)\n",
        "        if not os.path.exists(destination_path):\n",
        "            file_info.append(f\"File: {file.name}\")\n",
        "            copy_file(class_dir, file.name )\n",
        "    return f\"{len(file_info)} files uploaded.\"\n",
        "\n",
        "def delete_dataset():\n",
        "  shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "  os.makedirs(dataset_dir, exist_ok=True)\n",
        "  return \"Dataset deleted.\"\n",
        "\n",
        "def delete_class_images():\n",
        "  shutil.rmtree(class_dir, ignore_errors=True)\n",
        "  os.makedirs(class_dir, exist_ok=True)\n",
        "  return \"Class images deleted.\"\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion Dreambooth WebUI\")\n",
        "        gr.Markdown(\"Train Stable Diffusion model using preloaded weights.\")\n",
        "        with gr.Row():\n",
        "          with gr.Column():\n",
        "            with gr.Row():\n",
        "                file_input = gr.File(file_count=\"multiple\", label=\"Upload Dataset\",\n",
        "                  height=200, file_types=[\"image\"])\n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\"Upload Dataset\")\n",
        "                delete_data_btn = gr.Button(\"Delete Dataset\")\n",
        "            with gr.Row():\n",
        "                output = gr.Textbox(label=\"Results\")\n",
        "            submit_btn.click(fn=process_files, inputs=file_input, outputs=output)\n",
        "            delete_data_btn.click(fn=delete_dataset, outputs=output)\n",
        "          with gr.Column():\n",
        "            with gr.Row():\n",
        "                class_file_input = gr.File(file_count=\"multiple\", label=\"Upload Class Images\",\n",
        "                  height=200, file_types=[\"image\"])\n",
        "            with gr.Row():\n",
        "                class_submit_btn = gr.Button(\"Upload Class Images\")\n",
        "                class_delete_data_btn = gr.Button(\"Delete Class Images\")\n",
        "            with gr.Row():\n",
        "                class_output = gr.Textbox(label=\"Results\")\n",
        "            class_submit_btn.click(fn=process_class_files, inputs=class_file_input, outputs=class_output)\n",
        "            class_delete_data_btn.click(fn=delete_class_images, outputs=class_output)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                placeholder_token = gr.Textbox(label=\"Placeholder Token\", placeholder=\"Enter placeholder token here\", interactive=True)\n",
        "                class_token = gr.Textbox(label=\"Class Token\", placeholder=\"Enter class token here\", interactive=True)\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\", placeholder=\"Enter your prompt here\", interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps\", value=500, interactive=True)\n",
        "                learning_rate = gr.Textbox(label=\"Learning Rate\", value=\"1e-4\", interactive=True)\n",
        "                batch_size = gr.Number(label=\"Batch Size\", value=1, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview Steps\", value=25, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "                generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "                generate_button = gr.Button(\"Start Training\")\n",
        "                cancel_button = gr.Button(\"Cancel Training\")\n",
        "                reset_button = gr.Button(\"Reset Data\")\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[prompt, placeholder_token, class_token, num_training_steps,\n",
        "                    learning_rate, batch_size, preview_save_steps, preview_seed],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "        cancel_button.click(\n",
        "            fn=stop_training,\n",
        "            outputs=[generate_status]\n",
        "        )\n",
        "\n",
        "        reset_button.click(\n",
        "            fn=reset_data\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "demo = ui()\n",
        "demo.launch(share=True, debug=True)\n",
        "# demo.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZF3ivnHN3d7"
      },
      "outputs": [],
      "source": [
        "# 4. Test your Dreambooth model\n",
        "# You can try some prompt engineer which you learned in previous lessons.\n",
        "# The {token_name} will be replaced by the placeholder token you set previously.\n",
        "from diffusers import StableDiffusionPipeline, UNet2DConditionModel\n",
        "import torch\n",
        "\n",
        "preview_prompt = f\"{token_name}, a illustration. cyan, reflective, flower, 8k, lineart, extremly detailed eyes, digital painting. masterpiece, best quality.\"\n",
        "negative_prompt = \"grain, pattern, disfigured, kitsch, ugly, oversaturated, grain, low-res, Deformed, blurry, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, poorly drawn hands, missing limb, blurry, floating limbs, disconnected limbs, malformed hands, blur, out of focus, long neck, long body, disgusting, poorly drawn, childish, mutilated, mangled, old, surreal\"\n",
        "\n",
        "if pipeline is None:\n",
        "  pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "        base_model,\n",
        "        torch_dtype=torch.float16,\n",
        "  )\n",
        "\n",
        "  custom_unet = UNet2DConditionModel.from_pretrained(\n",
        "        os.path.join(output_dir, \"unet\"),\n",
        "        torch_dtype=torch.float16,\n",
        "  )\n",
        "  pipeline.unet = custom_unet\n",
        "  pipeline.to(\"cuda\")\n",
        "\n",
        "  # pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "  #     output_dir,\n",
        "  #     torch_dtype=torch.float16,\n",
        "  # ).to(\"cuda\")\n",
        "\n",
        "output = pipeline(\n",
        "    preview_prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7,\n",
        ")\n",
        "\n",
        "display(output.images[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Save Dreambooth modle\n",
        "# It will load the SD1.5 and replce the UNet part, then combine into a safetensors.\n",
        "\n",
        "def combine_unet_to_pretrain(\n",
        "    revision=None,\n",
        "    variant=None,\n",
        "    safe_serialization=True,\n",
        "    **pipeline_args,\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a base pipeline, swaps in the UNet saved by `save_unet`, normalizes scheduler,\n",
        "    and saves a full DiffusionPipeline to out_dir/.\n",
        "    \"\"\"\n",
        "    from diffusers import DiffusionPipeline, UNet2DConditionModel\n",
        "\n",
        "    # Load base pipeline (text encoder, VAE, scheduler, etc.)\n",
        "    pipe = DiffusionPipeline.from_pretrained(\n",
        "        \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "        revision=revision,\n",
        "        variant=variant,\n",
        "        **pipeline_args,\n",
        "    )\n",
        "\n",
        "    # Load your trained UNet and plug it in\n",
        "    new_unet = UNet2DConditionModel.from_pretrained(os.path.join(output_dir, \"unet\"))\n",
        "\n",
        "    pipe.unet = new_unet\n",
        "\n",
        "    # (Optional) Normalize scheduler variance behavior (same logic you had)\n",
        "    scheduler_args = {}\n",
        "    if \"variance_type\" in pipe.scheduler.config:\n",
        "        vtype = pipe.scheduler.config.variance_type\n",
        "        if vtype in [\"learned\", \"learned_range\"]:\n",
        "            vtype = \"fixed_small\"\n",
        "        scheduler_args[\"variance_type\"] = vtype\n",
        "    pipe.scheduler = pipe.scheduler.from_config(pipe.scheduler.config, **scheduler_args)\n",
        "\n",
        "    # Save the full pipeline\n",
        "    pipe.save_pretrained(output_dir, safe_serialization=safe_serialization)\n",
        "    print(f\"[combine_unet_to_pretrain] Full pipeline saved to: {output_dir}\")\n",
        "    !python convert_diffusers_to_original_stable_diffusion.py --model_path {output_dir} --checkpoint_path model.safetensors --use_safetensors\n",
        "    print(f\"model.safetensors is created.\")\n",
        "\n",
        "combine_unet_to_pretrain()"
      ],
      "metadata": {
        "id": "Xn7DVV2-SQuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRT9Vuo9bdq0"
      },
      "outputs": [],
      "source": [
        "# 6. Download your model.savetensors\n",
        "# If you are using Colab, you can mount Google Drive and upload your model.safetensors\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Create a directory in Google Drive if it doesn't exist\n",
        "    import os\n",
        "    target_dir = \"/content/drive/MyDrive/Dreambooth\"\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "        print(f\"Created directory: {target_dir}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {target_dir}\")\n",
        "\n",
        "    # Copy your file to Drive\n",
        "    !cp /content/model.safetensors {target_dir}/{token_name}.safetensors\n",
        "    print(f\"Your Dreambooth model has been uploaded to your Google Drive folder {target_dir}\")\n",
        "except:\n",
        "  pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mrfuGAI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}