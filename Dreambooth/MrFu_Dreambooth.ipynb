{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hBByDHe3Su6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Package installation finished.\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "# On Windows, you just need to execute this cell for once.\n",
        "try:\n",
        "    import google.colab\n",
        "    # IN_COLAB = True\n",
        "except ImportError:\n",
        "    # IN_COLAB = False\n",
        "    %pip install -q git+https://github.com/huggingface/transformers\n",
        "    %pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "%pip install -q git+https://github.com/huggingface/diffusers\n",
        "%pip install -q gradio ftfy tensorboard\n",
        "%pip install -q bitsandbytes\n",
        "#%pip install -U git+https://github.com/TimDettmers/bitsandbytes.git\n",
        "%pip install -q xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "#%pip install -U git+https://github.com/facebookresearch/xformers.git@main\n",
        "print(\"Package installation finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9gVoVoNmnsrN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_dreambooth.py already exists, skipping download.\n",
            "convertosdv2.py already exists, skipping download.\n"
          ]
        }
      ],
      "source": [
        "# Create folders and download training scripts\n",
        "import os, shutil\n",
        "\n",
        "dataset_dir = \"./dataset\"\n",
        "output_dir = \"./output\"\n",
        "logging_dir = \"./log\"\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "# Delete the 'output' folder and its contents\n",
        "shutil.rmtree(output_dir, ignore_errors=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "# Delete the 'log' folder and its contents\n",
        "shutil.rmtree(logging_dir, ignore_errors=True)\n",
        "os.makedirs(logging_dir, exist_ok=True)\n",
        "\n",
        "# fetch train_dreambooth.py if it doesn't exist\n",
        "if not os.path.exists(\"train_dreambooth.py\"):\n",
        "    !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/Dreambooth/train_dreambooth.py\n",
        "else:\n",
        "    print(\"train_dreambooth.py already exists, skipping download.\")\n",
        "\n",
        "# fetch convertosdv2.py if it doesn't exist\n",
        "if not os.path.exists(\"convertosdv2.py\"):\n",
        "    !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/Dreambooth/convertosdv2.py\n",
        "else:\n",
        "    print(\"convertosdv2.py already exists, skipping download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3bzS-g4hcUs0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File sks_e000020_00_20250313013834.png saved to ./dataset\n",
            "File sks_e000022_00_20250313013841.png saved to ./dataset\n",
            "File sks_e000024_00_20250313013847.png saved to ./dataset\n",
            "File sks_e000026_00_20250313013854.png saved to ./dataset\n"
          ]
        }
      ],
      "source": [
        "# Upload dataset images\n",
        "try:\n",
        "    from google.colab import files\n",
        "    import os\n",
        "\n",
        "    # Define the target directory where you want to upload your files\n",
        "    # Replace with your specific folder path\n",
        "    target_directory = dataset_dir\n",
        "\n",
        "    # Upload files from local machine\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move the uploaded files to the target directory\n",
        "    for filename in uploaded.keys():\n",
        "        # Get source and destination paths\n",
        "        source_path = filename\n",
        "        destination_path = os.path.join(target_directory, filename)\n",
        "\n",
        "        # Move the file\n",
        "        !mv \"{source_path}\" \"{destination_path}\"\n",
        "        print(f\"Moved {filename} to {target_directory}\")\n",
        "    \n",
        "except ImportError:\n",
        "    import tkinter as tk\n",
        "    from tkinter import filedialog\n",
        "    import os\n",
        "\n",
        "    # Initialize tkinter\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()  # Hide the root window\n",
        "    root.attributes('-topmost',True)\n",
        "\n",
        "    # Open a file dialog and allow multiple file selection\n",
        "    file_paths = filedialog.askopenfilenames(\n",
        "        title='Select Dataset Images',\n",
        "        filetypes=[('Image Files', '*.png;*.jpg;*.jpeg;*.bmp;*.gif')]\n",
        "    )\n",
        "    root.destroy()\n",
        "\n",
        "    # Define the target directory\n",
        "    target_directory = dataset_dir\n",
        "\n",
        "    # Copy or move files to the target directory\n",
        "    for file_path in file_paths:\n",
        "        filename = os.path.basename(file_path)\n",
        "        destination = os.path.join(target_directory, filename)\n",
        "        os.rename(file_path, destination)  # or use shutil.copy for copying\n",
        "        print(f'File {filename} saved to {target_directory}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0wl0d-1HlRJZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A matching Triton is not available, some optimizations will not be enabled\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\anaconda3\\envs\\diffusion\\lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\n",
            "    import triton  # noqa\n",
            "ModuleNotFoundError: No module named 'triton'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Command: accelerate launch train_dreambooth.py --pretrained_model_name_or_path stable-diffusion-v1-5/stable-diffusion-v1-5 --instance_data_dir dataset --instance_prompt sks --output_dir ./output --train_batch_size 1 --resolution 512 --lr_scheduler constant --learning_rate 5e-06 --lr_warmup_steps 0 --gradient_accumulation_steps 1 --num_validation_images 1 --validation_prompt sks --validation_steps 25 --max_train_steps 500 --mixed_precision fp16 --use_8bit_adam --gradient_checkpointing --enable_xformers_memory_efficient_attention --set_grads_to_none --logging_dir ./log --seed 1 --checkpointing_steps 501\n"
          ]
        }
      ],
      "source": [
        "# Create a WebUI for training\n",
        "# It will download the SD v1.5 for the 1st time training\n",
        "import gradio as gr\n",
        "import sys\n",
        "import threading\n",
        "#from textual_inversion import main as train_textual_inversion  # Assuming main function is the entry point in textual_inversion.py\n",
        "from train_dreambooth import main as train_dreambooth\n",
        "import time, os, logging\n",
        "from os import path\n",
        "import subprocess\n",
        "import shlex\n",
        "import queue\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status\n",
        "    current_preview = image\n",
        "    current_status = f\"Preview updated at step {step}\"\n",
        "\n",
        "def run_training(dataset_path, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                 learning_rate, batch_size, preview_save_steps, preview_seed):\n",
        "    global current_preview, current_status\n",
        "    current_preview = None  # Reset the preview\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "\n",
        "    # Define DreamBooth training parameters as a list of command-line arguments.\n",
        "    # Adjust the paths, prompts, and hyperparameters to match your experiment.\n",
        "    command = [\n",
        "        \"accelerate\", \"launch\", \"train_dreambooth.py\",\n",
        "        \"--pretrained_model_name_or_path\", \"stable-diffusion-v1-5/stable-diffusion-v1-5\",  # or your chosen model\n",
        "        \"--instance_data_dir\", dataset_path,  # folder with your subject images\n",
        "        \"--instance_prompt\", placeholder_token,  # prompt identifier for your subject\n",
        "        \"--output_dir\", output_dir,          # where to save your DreamBooth model\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--resolution\", \"512\",\n",
        "        \"--lr_scheduler\", \"constant\",\n",
        "        \"--learning_rate\", str(learning_rate),\n",
        "        \"--lr_warmup_steps\", \"0\",\n",
        "        \"--gradient_accumulation_steps\", \"1\",\n",
        "        \"--num_validation_images\", \"1\",\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--mixed_precision\", \"fp16\",\n",
        "        \"--use_8bit_adam\",\n",
        "        \"--gradient_checkpointing\",\n",
        "        \"--enable_xformers_memory_efficient_attention\",\n",
        "        \"--set_grads_to_none\",\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--seed\", str(preview_seed),\n",
        "        \"--checkpointing_steps\", str(num_training_steps+1),\n",
        "        # \"--class_data_dir\", \"./class_images\",        # folder with class images (for prior preservation)\n",
        "        # \"--class_prompt\", \"a photo of a person\",        # prompt for class images\n",
        "        # \"--with_prior_preservation\",           # enable prior preservation if you have class images\n",
        "        # \"--num_class_images\", \"100\",           # adjust based on your available class images\n",
        "        # Add other DreamBooth parameters as needed\n",
        "    ]\n",
        "\n",
        "    # Parse the arguments using the DreamBooth parser\n",
        "    #args = train_dreambooth.parse_args(args_list)\n",
        "\n",
        "    # Now, call the main function to start training\n",
        "    #train_dreambooth.main(args)\n",
        "\n",
        "\n",
        "    # Print the command for debugging\n",
        "    print(\"Command:\", \" \".join(command))\n",
        "    # temp = \" \".join(command)\n",
        "    yield None, gr.update(value=\"Training...\")\n",
        "\n",
        "    # Disable logging\n",
        "    logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    # Run the command in a separate process\n",
        "    global process\n",
        "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Wait for the process to complete\n",
        "    stdout, stderr = process.communicate()\n",
        "\n",
        "    # Print the output and errors (for debugging)\n",
        "    print(\"Output:\", stdout.decode())\n",
        "    print(\"Errors:\", stderr.decode())\n",
        "\n",
        "    # Update status when training completes\n",
        "    current_status = \"Converting model...\"\n",
        "    yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "    !python convertosdv2.py --fp16 {output_dir} \"model.ckpt\"\n",
        "\n",
        "    current_status = \"Training completed!\"\n",
        "    yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion Dreambooth WebUI\")\n",
        "        gr.Markdown(\"Train Stable Diffusion model using preloaded weights.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            dataset_path = gr.Textbox(label=\"Dataset Path\", value=\"dataset\", interactive=True)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                placeholder_token = gr.Textbox(label=\"Placeholder Token\", placeholder=\"Enter placeholder token here\", interactive=True)\n",
        "                class_token = gr.Textbox(label=\"Class Token (not implemented yet)\", placeholder=\"Not implemented yet\", interactive=False)\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\", placeholder=\"Enter your prompt here\", interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps\", value=500, interactive=True)\n",
        "                learning_rate = gr.Number(label=\"Learning Rate\", value=0.000005, interactive=True)\n",
        "                batch_size = gr.Number(label=\"Batch Size\", value=1, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview Steps\", value=25, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "        generate_button = gr.Button(\"Start Training\")\n",
        "\n",
        "        generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[dataset_path, prompt, placeholder_token, class_token, num_training_steps,\n",
        "                    learning_rate, batch_size, preview_save_steps, preview_seed],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "demo = ui()\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6owcy6kvIj44"
      },
      "outputs": [],
      "source": [
        "# Loads the logs in TensorBoard\n",
        "# If you are using Windows, open http://localhost:8888 in browser\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=log/ --host localhost --port 8888"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRT9Vuo9bdq0"
      },
      "outputs": [],
      "source": [
        "# If you are using Colab, you can mount Google Drive and upload your model.ckpt\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Create a directory in Google Drive if it doesn't exist\n",
        "    import os\n",
        "    target_dir = \"/content/drive/MyDrive/Dreambooth\"\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "        print(f\"Created directory: {target_dir}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {target_dir}\")\n",
        "\n",
        "    # Copy your file to Drive\n",
        "    !cp /content/model.ckpt {target_dir}/model.ckpt\n",
        "    print(f\"Your Dreambooth model has been uploaded to your Google Drive folder {target_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg-WlvSVsA_g",
        "outputId": "eb61caea-d110-4f31-aa3f-c3ab820421ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "# Force terminate the WebUI and training process\n",
        "demo.close()\n",
        "process.kill()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "diffusion",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
