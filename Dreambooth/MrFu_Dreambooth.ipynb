{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBByDHe3Su6a"
      },
      "outputs": [],
      "source": [
        "# 1. Install the required packages\n",
        "# On Windows, you just need to execute this cell for once.\n",
        "try:\n",
        "    import google.colab\n",
        "    # IN_COLAB = True\n",
        "except ImportError:\n",
        "    # IN_COLAB = False\n",
        "    %pip install -q git+https://github.com/huggingface/transformers\n",
        "    %pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "%pip install -q git+https://github.com/huggingface/diffusers\n",
        "%pip install -q gradio ftfy tensorboard\n",
        "%pip install -q bitsandbytes\n",
        "#%pip install -U git+https://github.com/TimDettmers/bitsandbytes.git\n",
        "%pip install -q xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "#%pip install -U git+https://github.com/facebookresearch/xformers.git@main\n",
        "print(\"Package installation finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gVoVoNmnsrN"
      },
      "outputs": [],
      "source": [
        "# 2. Create folders and download training scripts\n",
        "import os, shutil\n",
        "\n",
        "dataset_dir = \"./dataset\"\n",
        "output_dir = \"./output\"\n",
        "logging_dir = \"./log\"\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "# Delete the 'output' folder and its contents\n",
        "shutil.rmtree(output_dir, ignore_errors=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "# Delete the 'log' folder and its contents\n",
        "shutil.rmtree(logging_dir, ignore_errors=True)\n",
        "os.makedirs(logging_dir, exist_ok=True)\n",
        "# Delete the 'dataset' folder and its contents\n",
        "# shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "# os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# fetch train_dreambooth.py if it doesn't exist\n",
        "if not os.path.exists(\"train_dreambooth.py\"):\n",
        "    !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/Dreambooth/train_dreambooth.py\n",
        "else:\n",
        "    print(\"train_dreambooth.py already exists, skipping download.\")\n",
        "\n",
        "# fetch convertosdv2.py if it doesn't exist\n",
        "if not os.path.exists(\"convert_diffusers_to_original_stable_diffusion.py\"):\n",
        "    !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/Dreambooth/convert_diffusers_to_original_stable_diffusion.py\n",
        "else:\n",
        "    print(\"convert_diffusers_to_original_stable_diffusion.py already exists, skipping download.\")\n",
        "\n",
        "ipynb_checkpoints = os.path.join( dataset_dir, \".ipynb_checkpoints\")\n",
        "shutil.rmtree(\".gradio\", ignore_errors=True)\n",
        "shutil.rmtree(\".config\", ignore_errors=True)\n",
        "shutil.rmtree(ipynb_checkpoints, ignore_errors=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bzS-g4hcUs0"
      },
      "outputs": [],
      "source": [
        "# 3. Upload dataset images\n",
        "def load_dataset():\n",
        "  try:\n",
        "    from google.colab import files\n",
        "    import os\n",
        "\n",
        "    # Upload files from local machine\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move the uploaded files to the target directory\n",
        "    for filename in uploaded.keys():\n",
        "        # Get source and destination paths\n",
        "        source_path = filename\n",
        "        destination_path = os.path.join(dataset_dir, filename)\n",
        "\n",
        "        # Move the file\n",
        "        !mv \"{source_path}\" \"{destination_path}\"\n",
        "        print(f\"Moved {filename} to {dataset_dir}\")\n",
        "\n",
        "  except ImportError:\n",
        "    import tkinter as tk\n",
        "    from tkinter import filedialog\n",
        "    import os\n",
        "\n",
        "    # Initialize tkinter\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()  # Hide the root window\n",
        "    root.attributes('-topmost',True)\n",
        "\n",
        "    # Open a file dialog and allow multiple file selection\n",
        "    file_paths = filedialog.askopenfilenames(\n",
        "        title='Select Dataset Images',\n",
        "        filetypes=[('Image Files', '*.png;*.jpg;*.jpeg;*.bmp;*.gif')]\n",
        "    )\n",
        "    root.destroy()\n",
        "\n",
        "    # Define the target directory\n",
        "    target_directory = dataset_dir\n",
        "\n",
        "    # Copy or move files to the target directory\n",
        "    for file_path in file_paths:\n",
        "        filename = os.path.basename(file_path)\n",
        "        destination = os.path.join(target_directory, filename)\n",
        "        os.rename(file_path, destination)  # or use shutil.copy for copying\n",
        "        print(f'File {filename} saved to {target_directory}')\n",
        "\n",
        "load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wl0d-1HlRJZ"
      },
      "outputs": [],
      "source": [
        "# 4. Create a WebUI for training\n",
        "# It will download the SD v1.5 for the 1st time training\n",
        "# A very good reference:\n",
        "# https://www.reddit.com/r/StableDiffusion/comments/ybxv7h/good_dreambooth_formula/\n",
        "\n",
        "import gradio as gr\n",
        "import sys\n",
        "import threading\n",
        "#from textual_inversion import main as train_textual_inversion  # Assuming main function is the entry point in textual_inversion.py\n",
        "# from train_dreambooth import main as train_dreambooth\n",
        "import time, os, logging\n",
        "from os import path\n",
        "import subprocess\n",
        "import shlex\n",
        "import queue\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status\n",
        "    current_preview = image\n",
        "    current_status = f\"Preview updated at step {step}\"\n",
        "\n",
        "def run_training(dataset_path, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                 learning_rate, batch_size, preview_save_steps, preview_seed):\n",
        "    global current_preview, current_status\n",
        "    current_preview = None  # Reset the preview\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "\n",
        "    # Define DreamBooth training parameters as a list of command-line arguments.\n",
        "    # Adjust the paths, prompts, and hyperparameters to match your experiment.\n",
        "    command = [\n",
        "        \"accelerate\", \"launch\", \"train_dreambooth.py\",\n",
        "        \"--pretrained_model_name_or_path\", \"stable-diffusion-v1-5/stable-diffusion-v1-5\",  # or your chosen model\n",
        "        \"--instance_data_dir\", dataset_path,  # folder with your subject images\n",
        "        \"--instance_prompt\", placeholder_token,  # prompt identifier for your subject\n",
        "        \"--output_dir\", output_dir,          # where to save your DreamBooth model\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--resolution\", \"512\",\n",
        "        \"--lr_scheduler\", \"linear\",\n",
        "        \"--learning_rate\", str(learning_rate),\n",
        "        \"--lr_warmup_steps\", \"0\",\n",
        "        \"--gradient_accumulation_steps\", \"1\",\n",
        "        \"--num_validation_images\", \"1\",\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--mixed_precision\", \"fp16\",\n",
        "        \"--use_8bit_adam\",\n",
        "        \"--gradient_checkpointing\",\n",
        "        \"--enable_xformers_memory_efficient_attention\",\n",
        "        \"--set_grads_to_none\",\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--seed\", str(preview_seed),\n",
        "        \"--checkpointing_steps\", str(num_training_steps+1),\n",
        "        # \"--train_only_unet\",\n",
        "\n",
        "\n",
        "        # \"--class_data_dir\", \"./class_images\",        # folder with class images (for prior preservation)\n",
        "        # \"--class_prompt\", \"a photo of a person\",        # prompt for class images\n",
        "        # \"--with_prior_preservation\",           # enable prior preservation if you have class images\n",
        "        # \"--num_class_images\", \"100\",           # adjust based on your available class images\n",
        "        # Add other DreamBooth parameters as needed\n",
        "    ]\n",
        "\n",
        "    # Parse the arguments using the DreamBooth parser\n",
        "    #args = train_dreambooth.parse_args(args_list)\n",
        "\n",
        "    # Now, call the main function to start training\n",
        "    #train_dreambooth.main(args)\n",
        "\n",
        "\n",
        "    # Print the command for debugging\n",
        "    print(\"Command:\", \" \".join(command))\n",
        "    # temp = \" \".join(command)\n",
        "    yield None, gr.update(value=\"Training...\")\n",
        "\n",
        "    # Disable logging\n",
        "    logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    # Run the command in a separate process\n",
        "    global process\n",
        "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Wait for the process to complete\n",
        "    stdout, stderr = process.communicate()\n",
        "\n",
        "    # Print the output and errors (for debugging)\n",
        "    print(\"Output:\", stdout.decode())\n",
        "    print(\"Errors:\", stderr.decode())\n",
        "\n",
        "    # Update status when training completes\n",
        "    current_status = \"Converting model...\"\n",
        "    yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "\n",
        "    global pipeline\n",
        "    pipeline=None\n",
        "    !python convert_diffusers_to_original_stable_diffusion.py --model_path {output_dir} --checkpoint_path model.safetensors --use_safetensors\n",
        "    current_status = \"Training completed!\"\n",
        "    process.kill()\n",
        "    yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion Dreambooth WebUI\")\n",
        "        gr.Markdown(\"Train Stable Diffusion model using preloaded weights.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            dataset_path = gr.Textbox(label=\"Dataset Path\", value=\"dataset\", interactive=True)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                placeholder_token = gr.Textbox(label=\"Placeholder Token\", placeholder=\"Enter placeholder token here\", interactive=True)\n",
        "                class_token = gr.Textbox(label=\"Class Token (not implemented yet)\", placeholder=\"Not implemented yet\", interactive=False)\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\", placeholder=\"Enter your prompt here\", interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps\", value=500, interactive=True)\n",
        "                learning_rate = gr.Number(label=\"Learning Rate\", value=0.000005, interactive=True)\n",
        "                batch_size = gr.Number(label=\"Batch Size\", value=4, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview Steps\", value=25, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "        generate_button = gr.Button(\"Start Training\")\n",
        "\n",
        "        generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[dataset_path, prompt, placeholder_token, class_token, num_training_steps,\n",
        "                    learning_rate, batch_size, preview_save_steps, preview_seed],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "demo = ui()\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6owcy6kvIj44"
      },
      "outputs": [],
      "source": [
        "# 5. Loads the logs in TensorBoard\n",
        "# If you are using Windows, open http://localhost:8888 in browser\n",
        "# Enable auto update for each 30 seconds, look into Image tab and wait for update.\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=log/ --host localhost --port 8888"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Test the Dreambooth model\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "preview_prompt = \"wpg, a illustration of wpg. cyan, reflective, flower, 8k, lineart, extremly detailed eyes, digital painting. masterpiece, best quality.\"\n",
        "negative_prompt = \"vibrant color, grain, pattern, disfigured, kitsch, ugly, oversaturated, grain, low-res, Deformed, blurry, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, poorly drawn hands, missing limb, blurry, floating limbs, disconnected limbs, malformed hands, blur, out of focus, long neck, long body, disgusting, poorly drawn, childish, mutilated, mangled, old, surreal\"\n",
        "\n",
        "if pipeline is None:\n",
        "  pipeline = StableDiffusionPipeline.from_single_file(\n",
        "      \"model.safetensors\",\n",
        "      negative_prompt=negative_prompt,\n",
        "      torch_dtype=torch.float16,\n",
        "  ).to(\"cuda\")\n",
        "\n",
        "output = pipeline(\n",
        "    \"wpg\",\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7,\n",
        ")\n",
        "\n",
        "display(output.images[0])"
      ],
      "metadata": {
        "id": "4ZF3ivnHN3d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRT9Vuo9bdq0"
      },
      "outputs": [],
      "source": [
        "# 7. Download your model.savetensors\n",
        "# If you are using Colab, you can mount Google Drive and upload your model.safetensors\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Create a directory in Google Drive if it doesn't exist\n",
        "    import os\n",
        "    target_dir = \"/content/drive/MyDrive/Dreambooth\"\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "        print(f\"Created directory: {target_dir}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {target_dir}\")\n",
        "\n",
        "    # Copy your file to Drive\n",
        "    !cp /content/model.safetensors {target_dir}/model.safetensors\n",
        "    print(f\"Your Dreambooth model has been uploaded to your Google Drive folder {target_dir}\")\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg-WlvSVsA_g"
      },
      "outputs": [],
      "source": [
        "# Force terminate the WebUI and training process\n",
        "demo.close()\n",
        "process.kill()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}