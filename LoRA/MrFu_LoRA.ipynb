{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBByDHe3Su6a"
      },
      "outputs": [],
      "source": [
        "# 1. Install the required packages\n",
        "# On Windows, you just need to execute this cell for once.\n",
        "try:\n",
        "    import google.colab\n",
        "    # IN_COLAB = True\n",
        "except ImportError:\n",
        "    # IN_COLAB = False\n",
        "    %pip install -q git+https://github.com/huggingface/transformers\n",
        "    %pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "%pip install -q git+https://github.com/huggingface/diffusers\n",
        "%pip install -q gradio ftfy tensorboard peft\n",
        "%pip install -q bitsandbytes\n",
        "#%pip install -U git+https://github.com/TimDettmers/bitsandbytes.git\n",
        "%pip install -q xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "#%pip install -U git+https://github.com/facebookresearch/xformers.git@main\n",
        "print(\"Package installation finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gVoVoNmnsrN"
      },
      "outputs": [],
      "source": [
        "# 2. Create folders and download training scripts\n",
        "import os, shutil\n",
        "\n",
        "dataset_dir = \"./dataset\"\n",
        "output_dir = \"./output\"\n",
        "logging_dir = \"./logs\"\n",
        "class_dir = \"./class\"\n",
        "\n",
        "token_name = \"sks\"\n",
        "pipeline = None\n",
        "\n",
        "def reset_data():\n",
        "  # Create the directories if they don't exist\n",
        "  os.makedirs(dataset_dir, exist_ok=True)\n",
        "  # Delete the 'output' folder and its contents\n",
        "  shutil.rmtree(output_dir, ignore_errors=True)\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "  # Delete the 'log' folder and its contents\n",
        "  shutil.rmtree(logging_dir, ignore_errors=True)\n",
        "  os.makedirs(logging_dir, exist_ok=True)\n",
        "  # Delete the 'class' folder and its contents\n",
        "  # shutil.rmtree(class_dir, ignore_errors=True)\n",
        "  os.makedirs(class_dir, exist_ok=True)\n",
        "  # Delete the 'dataset' folder and its contents\n",
        "  # shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "  # os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    # fetch train_dreambooth.py if it doesn't exist\n",
        "    if not os.path.exists(\"train_dreambooth_lora.py\"):\n",
        "        !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/LoRA/train_dreambooth_lora.py\n",
        "    else:\n",
        "        print(\"train_dreambooth_lora.py already exists, skipping download.\")\n",
        "\n",
        "    # fetch convertosdv2.py if it doesn't exist\n",
        "    if not os.path.exists(\"convert_diffusers_to_original_stable_diffusion.py\"):\n",
        "        !wget https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/utils/convert_diffusers_to_original_stable_diffusion.py\n",
        "    else:\n",
        "        print(\"convert_diffusers_to_original_stable_diffusion.py already exists, skipping download.\")\n",
        "except ImportError:\n",
        "    # fetch train_dreambooth.py if it doesn't exist\n",
        "    if not os.path.exists(\"train_dreambooth_lora.py\"):\n",
        "        !curl -O https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/LoRA/train_dreambooth_lora.py\n",
        "    else:\n",
        "        print(\"train_dreambooth_lora.py already exists, skipping download.\")\n",
        "\n",
        "    # fetch convertosdv2.py if it doesn't exist\n",
        "    if not os.path.exists(\"convert_diffusers_to_original_stable_diffusion.py\"):\n",
        "        !curl -O https://raw.githubusercontent.com/jomo0825/MrFuGenerativeAI/main/utils/convert_diffusers_to_original_stable_diffusion.py\n",
        "    else:\n",
        "        print(\"convert_diffusers_to_original_stable_diffusion.py already exists, skipping download.\")\n",
        "\n",
        "ipynb_checkpoints = os.path.join( dataset_dir, \".ipynb_checkpoints\")\n",
        "shutil.rmtree(\".gradio\", ignore_errors=True)\n",
        "shutil.rmtree(\".config\", ignore_errors=True)\n",
        "shutil.rmtree(ipynb_checkpoints, ignore_errors=True)\n",
        "\n",
        "reset_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wl0d-1HlRJZ"
      },
      "outputs": [],
      "source": [
        "# 3. Create a WebUI for LoRA Dreambooth training\n",
        "# It will download the SD v1.5 for the 1st time training\n",
        "# A very good reference:\n",
        "# https://www.reddit.com/r/StableDiffusion/comments/ybxv7h/good_dreambooth_formula/\n",
        "\n",
        "import gradio as gr\n",
        "import sys\n",
        "import threading\n",
        "from train_dreambooth_lora import main as train_dreambooth_lora\n",
        "from train_dreambooth_lora import parse_args\n",
        "import time, os, logging, shutil\n",
        "from os import path\n",
        "import subprocess\n",
        "import shlex\n",
        "import queue\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status, max_train_steps, current_step\n",
        "    current_step = step\n",
        "    current_preview = image\n",
        "    print(f\"{step}/{max_train_steps}\")\n",
        "\n",
        "def stop_training():\n",
        "    global stop_flag\n",
        "    stop_flag.set()\n",
        "    return gr.update(value=\"Training will be stopped...Waiting for the final preview...\")\n",
        "\n",
        "def run_training(prompt, neg_prompt, instance_prompt, class_prompt, num_class_images, num_training_steps,\n",
        "                learning_rate, batch_size, preview_save_steps, preview_seed, rank):\n",
        "    global current_preview, current_status, max_train_steps, token_name\n",
        "    global current_step, finish_event, stop_flag, pipeline\n",
        "    current_preview = None  # Reset the preview\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "    token_name = instance_prompt\n",
        "    pipeline = None\n",
        "\n",
        "    # Define LoRA DreamBooth training parameters as a list of command-line arguments.\n",
        "    command = [\n",
        "        \"--pretrained_model_name_or_path\", \"stable-diffusion-v1-5/stable-diffusion-v1-5\",  # or your chosen model\n",
        "        \"--instance_data_dir\", dataset_dir,  # folder with your subject images\n",
        "        \"--instance_prompt\", instance_prompt,  # prompt identifier for your subject\n",
        "        \"--output_dir\", output_dir,          # where to save your LoRA model\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--resolution\", \"512\",\n",
        "        \"--lr_scheduler\", \"cosine\",\n",
        "        \"--learning_rate\", learning_rate,\n",
        "        \"--lr_warmup_steps\", \"0\",\n",
        "        \"--gradient_accumulation_steps\", \"1\",\n",
        "        \"--num_validation_images\", \"1\",\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--validation_neg_prompt\", neg_prompt,\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--mixed_precision\", \"no\",\n",
        "        \"--use_8bit_adam\",\n",
        "        \"--gradient_checkpointing\",\n",
        "        \"--enable_xformers_memory_efficient_attention\",\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--seed\", str(preview_seed),\n",
        "        \"--checkpointing_steps\", str(num_training_steps+1),\n",
        "        \"--rank\", str(rank),  # LoRA rank parameter\n",
        "        \"--output_kohya_format\",\n",
        "        \"--train_text_encoder\",\n",
        "\n",
        "        \"--class_data_dir\", class_dir,          # folder with class images (for prior preservation)\n",
        "        \"--class_prompt\", class_prompt,         # prompt for class images\n",
        "        \"--with_prior_preservation\",            # enable prior preservation if you have class images\n",
        "        \"--num_class_images\", num_class_images, # adjust based on your available class images\n",
        "    ]\n",
        "\n",
        "    args = parse_args(command)\n",
        "    max_train_steps = args.max_train_steps\n",
        "\n",
        "    # Print the command for debugging\n",
        "    print(\"Command:\", \" \".join(command))\n",
        "\n",
        "    # Disable logging\n",
        "    logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    def worker(finish_event, stop_flag):\n",
        "        try:\n",
        "            train_dreambooth_lora(args, {\"_callback\": preview_callback, \"stop_flag\": stop_flag})\n",
        "        except Exception as e:\n",
        "            print(f\"Training error: {e}\")\n",
        "        finally:\n",
        "            finish_event.set()\n",
        "\n",
        "    finish_event = threading.Event()\n",
        "    stop_flag = threading.Event()\n",
        "    finish_event.clear()\n",
        "    stop_flag.clear()\n",
        "\n",
        "    train_thread = threading.Thread(target=worker, args=(finish_event, stop_flag))\n",
        "    train_thread.start()\n",
        "    yield gr.update(value=None), gr.update(value=f\"Training started.\")\n",
        "\n",
        "    while not finish_event.is_set():\n",
        "        if current_preview is not None:\n",
        "            yield gr.update(value=current_preview), gr.update(value=f\"Preview at {current_step} step.\")\n",
        "            current_preview = None\n",
        "        time.sleep(1)\n",
        "\n",
        "    train_thread.join()\n",
        "\n",
        "    # Update status when training completes\n",
        "    current_status = \"Saving LoRA model...\"\n",
        "    yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "    pipeline = None\n",
        "\n",
        "    # Save the model in a format compatible with original Stable Diffusion\n",
        "    try:\n",
        "        # subprocess.run([\"python\", \"convert_lora_to_safetensors.py\", \"--model_path\", output_dir, \"--checkpoint_path\", \"lora_model.safetensors\"], check=True)\n",
        "        current_status = \"LoRA model saved successfully!\"\n",
        "    except Exception as e:\n",
        "        current_status = f\"Error saving model: {e}\"\n",
        "\n",
        "    yield gr.update(value=current_preview), gr.update(value=current_status)\n",
        "\n",
        "# Define a function to move the selected file\n",
        "def copy_file(target_directory, file_path):\n",
        "    if file_path is not None:\n",
        "        filename = os.path.basename(file_path)\n",
        "        destination_path = os.path.join(target_directory, filename)\n",
        "        # test if the destination_path already exists\n",
        "        if not os.path.exists(destination_path):\n",
        "            shutil.copy(file_path, destination_path)\n",
        "            print(f\"Copy {filename} to {target_directory}\")\n",
        "        else:\n",
        "            print(f\"{filename} already exists.\")\n",
        "    else:\n",
        "        print(\"No file selected.\")\n",
        "\n",
        "def process_files(files):\n",
        "    file_info = []\n",
        "\n",
        "    # Make sure dataset directory exists\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "    for file in files:\n",
        "        fileBasename = os.path.basename(file)\n",
        "        destination_path = os.path.join(dataset_dir, fileBasename)\n",
        "        if not os.path.exists(destination_path):\n",
        "            file_info.append(f\"File: {file.name}\")\n",
        "            copy_file(dataset_dir, file.name)\n",
        "    return f\"{len(file_info)} files uploaded.\"\n",
        "\n",
        "def process_class_files(files):\n",
        "    file_info = []\n",
        "\n",
        "    # Make sure class directory exists\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    for file in files:\n",
        "        fileBasename = os.path.basename(file)\n",
        "        destination_path = os.path.join(class_dir, fileBasename)\n",
        "        if not os.path.exists(destination_path):\n",
        "            file_info.append(f\"File: {file.name}\")\n",
        "            copy_file(class_dir, file.name)\n",
        "    return f\"{len(file_info)} files uploaded.\"\n",
        "\n",
        "def delete_dataset():\n",
        "    shutil.rmtree(dataset_dir, ignore_errors=True)\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "    return \"Dataset deleted.\"\n",
        "\n",
        "def delete_class_images():\n",
        "    shutil.rmtree(class_dir, ignore_errors=True)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "    return \"Class images deleted.\"\n",
        "\n",
        "def reset_data():\n",
        "    delete_dataset()\n",
        "    delete_class_images()\n",
        "    return \"All data reset.\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "os.makedirs(class_dir, exist_ok=True)\n",
        "os.makedirs(logging_dir, exist_ok=True)\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion LoRA Dreambooth WebUI\")\n",
        "        gr.Markdown(\"Train Stable Diffusion model with LoRA for faster fine-tuning and lower memory usage.\")\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                with gr.Row():\n",
        "                    file_input = gr.File(file_count=\"multiple\", label=\"Upload Dataset\",\n",
        "                        height=200, file_types=[\"image\"])\n",
        "                with gr.Row():\n",
        "                    submit_btn = gr.Button(\"Upload Dataset\")\n",
        "                    delete_data_btn = gr.Button(\"Delete Dataset\")\n",
        "                with gr.Row():\n",
        "                    output = gr.Textbox(label=\"Results\")\n",
        "                submit_btn.click(fn=process_files, inputs=file_input, outputs=output)\n",
        "                delete_data_btn.click(fn=delete_dataset, outputs=output)\n",
        "            with gr.Column():\n",
        "                with gr.Row():\n",
        "                    class_file_input = gr.File(file_count=\"multiple\", label=\"Upload Class Images\",\n",
        "                        height=200, file_types=[\"image\"])\n",
        "                with gr.Row():\n",
        "                    class_submit_btn = gr.Button(\"Upload Class Images\")\n",
        "                    class_delete_data_btn = gr.Button(\"Delete Class Images\")\n",
        "                with gr.Row():\n",
        "                    class_output = gr.Textbox(label=\"Results\")\n",
        "                class_submit_btn.click(fn=process_class_files, inputs=class_file_input, outputs=class_output)\n",
        "                class_delete_data_btn.click(fn=delete_class_images, outputs=class_output)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                instance_prompt = gr.Textbox(label=\"Instance Prompt\",\n",
        "                    placeholder=\"The token name for this concept\", interactive=True)\n",
        "                class_prompt = gr.Textbox(label=\"Class Prompt\",\n",
        "                    placeholder=\"The class name of this concept\", interactive=True)\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\",\n",
        "                    placeholder=\"Preview positive prompt\", interactive=True)\n",
        "                neg_prompt = gr.Textbox(label=\"Preview Negative Prompt\",\n",
        "                    placeholder=\"Preview negative prompt\",\n",
        "                    value=\"grain, pattern, disfigured, kitsch, ugly, oversaturated, grain, low-res, Deformed, blurry, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, poorly drawn hands, missing limb, blurry, floating limbs, disconnected limbs, malformed hands, blur, out of focus, long neck, long body, disgusting, poorly drawn, childish, mutilated, mangled, old, surreal\", interactive=True)\n",
        "                num_class_images = gr.Number(label=\"Number of Class Images\", value=10, interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps (for 4 images)\", value=600, interactive=True)\n",
        "                learning_rate = gr.Textbox(label=\"Learning Rate\", value=\"1e-4\", interactive=True)\n",
        "                batch_size = gr.Number(label=\"Batch Size\", value=1, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview Steps\", value=20, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "                rank = gr.Slider(label=\"LoRA Rank\", minimum=1, maximum=128, value=32, step=1,\n",
        "                    info=\"Higher rank = more capacity but larger file size\")\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "                generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "                generate_button = gr.Button(\"Start Training\")\n",
        "                cancel_button = gr.Button(\"Cancel Training\")\n",
        "                reset_button = gr.Button(\"Reset Data\")\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[prompt, neg_prompt, instance_prompt, class_prompt, num_class_images,  num_training_steps,\n",
        "                    learning_rate, batch_size, preview_save_steps, preview_seed, rank],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "        cancel_button.click(\n",
        "            fn=stop_training,\n",
        "            outputs=[generate_status]\n",
        "        )\n",
        "\n",
        "        reset_button.click(\n",
        "            fn=reset_data,\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Initialize global variables\n",
        "current_preview = None\n",
        "current_status = \"Ready\"\n",
        "max_train_steps = 0\n",
        "current_step = 0\n",
        "token_name = \"\"\n",
        "finish_event = None\n",
        "stop_flag = None\n",
        "pipeline = None\n",
        "\n",
        "# Launch the UI\n",
        "demo = ui()\n",
        "# demo.launch(debug=True)\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg-WlvSVsA_g"
      },
      "outputs": [],
      "source": [
        "demo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZF3ivnHN3d7"
      },
      "outputs": [],
      "source": [
        "# Option#1: Test the LoRA model\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
        "import torch\n",
        "\n",
        "preview_prompt = f\"{token_name} \"\n",
        "negative_prompt = \"grain, pattern, disfigured, kitsch, ugly, oversaturated, grain, low-res, Deformed, blurry, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, poorly drawn hands, missing limb, blurry, floating limbs, disconnected limbs, malformed hands, blur, out of focus, long neck, long body, disgusting, poorly drawn, childish, mutilated, mangled, old, surreal\"\n",
        "\n",
        "if pipeline is None:\n",
        "  pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "      \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "      torch_dtype=torch.float16,\n",
        "  ).to(\"cuda\")\n",
        "\n",
        "pipeline.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "pipeline.load_lora_weights(output_dir, weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "scheduler_args = {}\n",
        "\n",
        "if \"variance_type\" in pipeline.scheduler.config:\n",
        "    variance_type = pipeline.scheduler.config.variance_type\n",
        "\n",
        "    if variance_type in [\"learned\", \"learned_range\"]:\n",
        "        variance_type = \"fixed_small\"\n",
        "\n",
        "    scheduler_args[\"variance_type\"] = variance_type\n",
        "\n",
        "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "\n",
        "output = pipeline(\n",
        "    preview_prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=20,\n",
        "    guidance_scale=5,\n",
        ")\n",
        "\n",
        "display(output.images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRT9Vuo9bdq0"
      },
      "outputs": [],
      "source": [
        "# 4. Download your .savetensors model to Colab\n",
        "# Mount your Google Drive and upload your LoRA model\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Create a directory in Google Drive if it doesn't exist\n",
        "    import os\n",
        "    target_dir = \"/content/drive/MyDrive/LoRA\"\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "        print(f\"Created directory: {target_dir}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {target_dir}\")\n",
        "\n",
        "    # Copy your file to Drive\n",
        "    !cp /content/{output_dir}/pytorch_lora_weights_kohya.safetensors {target_dir}/{token_name}_lora.safetensors\n",
        "    print(f\"Your Dreambooth model has been uploaded to your Google Drive folder {target_dir}\")\n",
        "except:\n",
        "  pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}